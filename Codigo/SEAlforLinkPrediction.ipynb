{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qMIOYlGSBfu0",
        "bLfzvjHjCjtD",
        "DxUloURTO32-",
        "9FE4M3ZNO8mt",
        "ZrXL8i0lWskp",
        "XrhoHClDkuho",
        "9FMJS7smdJMw",
        "8wObCgmydOJ6"
      ],
      "authorship_tag": "ABX9TyPHnkIjySiphbyL6QW8zQr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivanchis01/Proyecto_matematicas_del_aprendizaje_de_maquinas/blob/main/SEAlforLinkPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SEAL ML**\n",
        "Este notebook contiene la implementación para predicción de enlaces del algoritmo SEAL, explicado y con ciertas modificaciones para su correcto funcionamiento en Google Colab.\n",
        "\n",
        "Más información de SEAL puede ser encontrada en el siguiente enlace: https://muhanzhang.github.io/SEAL_website/SEAL.html\n",
        "El link al github original puede verse aquí: https://github.com/facebookresearch/SEAL_OGB"
      ],
      "metadata": {
        "id": "Vdu6GAdetPh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Para su correcto funcionamiento es necesario instalar primero las siguientes librerías**"
      ],
      "metadata": {
        "id": "qMIOYlGSBfu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ogb #OGB es una colección realista, vasta y diversa de datasets para machine learning de grafos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UQ76dDXrtmnp",
        "outputId": "01398652-3d00-41b5-9529-3b0ee24b4adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.3.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (71.0.4)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 #Instala PyTorch, una librería para la ejecución y modelamiento sencillo de algoritmos basados en machine learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ad8xONMYtugQ",
        "outputId": "a2331545-f956-4248-aa2a-d47073542ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "URgEBa9Wt7NX",
        "outputId": "abcbea99-ff3c-4d7d-9860-bb8c255ff50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-scatter -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0HUyCs0BvWIx",
        "outputId": "8173b56d-fc40-46eb-a8d1-47ecee90920d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt23cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-sparse -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1oBADhSgvYhU",
        "outputId": "42d03415-13b2-4710-a794-8c09066f59be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt23cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-geometric #torch-geometric es una librería construida sobre PyTorch para escribir y entrenar fácilmente redes neuronales gráficas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Mdj55YNwvZ8O",
        "outputId": "9b569c6f-32aa-4ee1-fec9-53dd3b4e442e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importamos ahora todas las librerías necesarias para desarrollar el proyecto**\n",
        "\n"
      ],
      "metadata": {
        "id": "bLfzvjHjCjtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os #Este módulo provee una manera versátil de usar funcionalidades dependientes del sistema operativo.\n",
        "import os.path as osp #Módulo que ofrece funciones útiles para las rutas\n",
        "import sys #Este módulo provee acceso a algunas variables usadas o mantenidas por el intérprete y a funciones que interactúan fuertemente con el intérprete.\n",
        "import copy as cp #Módulo que contiene un onjunto de funciones relacionadas con la copia de diferentes elementos de una lista, objetos, matrices, etc.\n",
        "import time #Este módulo proporciona varias funciones relacionadas con el tiempo.\n",
        "import math #Este módulo proporciona operaciones matemáticas\n",
        "import numpy as np #Este módulo facilita lass operaciones con matrices\n",
        "import random #Este módulo genera elementos de carácter pseudoaleatorio\n",
        "import pdb #El módulo pdbdefine un depurador de código fuente interactivo para programas Python.\n",
        "from tqdm import tqdm #Hace que los bucles muestren instantáneamente un medidor de progreso inteligente\n",
        "import warnings #Permite emitir mensajes de advertencia\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "#==============================TORCH==================================================\n",
        "\n",
        "import torch #Importa la librería torch\n",
        "from torch.nn import (ModuleList, Linear, Conv1d, MaxPool1d, Embedding, ReLU,\n",
        "                      Sequential, BatchNorm1d as BN)\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import BCEWithLogitsLoss #Importa una función de perdida que combina una capa sigmoide y la funcion de pérdida BCL\n",
        "from torch.utils.data import DataLoader #Representa un iterable de python sobre un dataset\n",
        "\n",
        "#=========================TORCH.GEOMETRIC=============================================\n",
        "\n",
        "from torch_geometric.nn import (GCNConv, SAGEConv, GINConv,\n",
        "                                global_sort_pool, global_add_pool, global_mean_pool) #Importa operadores para redes neuronales de grafos propuestas en distintos papers\n",
        "import torch_geometric.transforms as T #Las transformaciones son una forma general de modificar y personalizar objetos, ya sea pasándolos implícitamente como argumento a Dataset o aplicándolos explícitamente a objetos Data u individuales HeteroData\n",
        "from torch_geometric.datasets import Planetoid #Planetoid es un conjunto de datos que incluye tres conjuntos de datos (cora,citeseer,pubmed) que consistene en grafos de citas científicas, los nodos representan documentos y las aristas citas entre ellos\n",
        "                                                #la clase planetoid proporciona una forma sencilla de cargar y manejar estos conjuntos de datos\n",
        "from torch_geometric.datasets import Actor\n",
        "from torch_geometric.data import Data, Dataset, InMemoryDataset, DataLoader #Objeto de datos que describe un grafo homogéneo, clase base para la creación de grafos de dataset,\n",
        "                                                                             #Clase base de conjunto de datos para crear conjuntos de datos de gráficos que caben fácilmente en la memoria de la CPU\n",
        "                                                                              #Cargador de datos que fusiona objetos de datos de una clase torch_geometric.data.dataset en un mini lote (subconjunto del conjunto de datos total).\n",
        "from torch_geometric.utils import (negative_sampling, add_self_loops, #Muestrea aristas random negativas de un grafo dado, añade un auto-loop a cada nodo del grafo\n",
        "                                   train_test_split_edges)            #Divide las aristas de un torch_geometric.data.Data en aristas positivas y negativas para train/val/test\n",
        "from torch_geometric.utils import to_networkx, to_undirected#Convierte una instancia torch_geometric.data.Data a un networkx.Graph, to_undirected convierte el grafo dado en un grafo no dirigido\n",
        "from torch_sparse import coalesce #se utiliza para asegurarse de que un tensor de índices de un grafo (o un tensor disperso) esté en una forma estándar y optimizada.\n",
        "\n",
        "#===============================SCIPY==================================================\n",
        "import scipy.sparse as ssp #Paquete de matrices dispersas para datos numéricos\n",
        "from scipy.sparse.csgraph import shortest_path #Realiza una búsqueda de ruta más corta en un grafo positivo dirigido o no dirigido\n",
        "from scipy.sparse import SparseEfficiencyWarning #Se utiliza para alertar a los usuarios sobre posibles ineficiencias en las operaciones con matrices dispersas.\n",
        "warnings.simplefilter('ignore', SparseEfficiencyWarning)\n",
        "#===============================OTROS==================================================\n",
        "from shutil import copy #Copia un archivo en otro y retorna la ruta al nuevo archivo\n",
        "from sklearn.metrics import roc_auc_score #Calcula el area bajo la curva ROC(receiver operating characteristics) para un conjunto de predicciones; sirve para evaluar la capacidad de un modelo de clasificación binaria\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator #Importa datasets para probar el predecir las propiedades de las aristas(link prediction), Sirve para medir el rendimiento de los modelos en tareas de predicción de enlaces"
      ],
      "metadata": {
        "id": "TzKArsEb1pOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Veamos ahora un ejemplo de cada una de las librerías que hemos importado antes de proceder con el código** (NO ES NECESARIO EJECUTARLO)"
      ],
      "metadata": {
        "id": "DxUloURTO32-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *OS, Sys, copy, time, math, numpy, random, pdb, tqdm*"
      ],
      "metadata": {
        "id": "9FE4M3ZNO8mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_de_trabajo_actual= os.getcwd()\n",
        "print('(OS)Ruta de trabajo actual = ',ruta_de_trabajo_actual)\n",
        "argumentos_de_la_linea_de_comandos = sys.argv\n",
        "print('(SYS)Argumentos de la lista de comandos pasados al script de python = ',argumentos_de_la_linea_de_comandos)\n",
        "matrix=[1,2,3,4]\n",
        "copy_matrix=cp.copy(matrix)\n",
        "print('(COPY)Copia de la matriz = ',copy_matrix)\n",
        "hora=time.ctime(0)\n",
        "print('(TIME)Tiempo = ',hora)\n",
        "operacion_matematica = math.cos(math.pi /2)\n",
        "print('(MATH)Coseno de pi/2 = ',math.floor(operacion_matematica))\n",
        "array=[[2,2],[3,3]]\n",
        "numpy_array=np.array(array)\n",
        "print('(NUMPY)Numpy array = \\n',numpy_array)\n",
        "random_number=random.randint(200000000,300000000400)\n",
        "print('(RANDOM)Numero pseudoaleatorio = ',random_number)\n",
        "#pdb.set_trace() #Python se detiene y espera a que usted le diga qué hacer a continuación. Verás un (Pdb)mensaje. Esto significa que ahora está en pausa en el depurador interactivo y puede ingresar un comando.\n",
        "print('(TQDM)')\n",
        "for i in tqdm(range(10000000)):\n",
        "  a=5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROdTvdXrPb-g",
        "outputId": "0478c15d-ccfb-4501-80d6-cb887c11ae08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(OS)Ruta de trabajo actual =  /content\n",
            "(SYS)Argumentos de la lista de comandos pasados al script de python =  ['/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-d9ddee6a-c1ff-49a8-99a5-812e8fbaeea8.json']\n",
            "(COPY)Copia de la matriz =  [1, 2, 3, 4]\n",
            "(TIME)Tiempo =  Thu Jan  1 00:00:00 1970\n",
            "(MATH)Coseno de pi/2 =  0\n",
            "(NUMPY)Numpy array = \n",
            " [[2 2]\n",
            " [3 3]]\n",
            "(RANDOM)Numero pseudoaleatorio =  188157630408\n",
            "(TQDM)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000000/10000000 [00:05<00:00, 1714991.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *TORCH*"
      ],
      "metadata": {
        "id": "ZrXL8i0lWskp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from torch.nn import (ModuleList,Linear)\n",
        "##ModuleList se utiliza para contener una lista ordenada de módulos que componen un modelo de red neuronal.\n",
        "##Cada elemento en la lista es un módulo de PyTorch que puede ser una capa, una función de activación,\n",
        "##una operación personalizada, etc. Un modulo es la clase base de la que derivan todas las capas y modelos\n",
        "##en la biblioteca torch.nn. son los objetos que encapsulan los parámetros entrenables, las operaciones\n",
        "##y la lógica necesaria para realizar cálculos dentro de una red neuronal.\n",
        "#Linear recibe como input el tamaño de las muestras de input y las muestras de salida y crea una transformación que se ajuste a los tamaños indicados\n",
        "linears = ModuleList([Linear(3, 5) for i in range(10)]) ##Set de 10 transformadas LINEALES de input size 3 a output_size 5\n",
        "tensorRndom=torch.randn(4,3) ##tensor random de tamaño 4x3\n",
        "transLineal=linears[1](tensorRndom) ##Aplicamos la transformada lineal en el indice 1 del modulelist al tensorRandom\n",
        "print(transLineal)##Queda de tamaño (tensorRndom,Linear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9-uVOOM1vkm",
        "outputId": "00507be4-50fc-4206-9a61-db6a908bd2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2714, -0.2912, -0.3590,  0.6622,  0.2786],\n",
            "        [-0.0380,  0.4212, -0.7337, -0.4344, -0.1393],\n",
            "        [-0.3909, -0.6070, -0.5138,  0.9382,  0.5270],\n",
            "        [-0.2135,  0.4659,  0.1472,  0.9334, -0.2213]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Conv1d aplica una convolución 1D sobre una señal de entrada, toma como parámetros el numero de canales en la imagen de entrada, el numero de canales que producirá la convolución y el tamaño del kernel de convolución\n",
        "##El numero de canales en la entrada corresponde al m del size nxmxl del vector de entrada\n",
        "##El numero de canales en la salida corresponde al out del size in,out,k del conv1d\n",
        "##El tamaño del Kernel no puede ser más grande que el l del input_size\n",
        "m = Conv1d(1, 2, 2)\n",
        "input = torch.randn(3, 1, 10) #Generamos un tensor aleatorio de tamaño 3x2x4 [[....],[....]],[[....],[....]],[[....],[....]]\n",
        "output = m(input) ##Siempre tendrá el n del nxmxl del tensor de entrada\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3BISeWc5I3H",
        "outputId": "4cdf85f8-db64-4e94-d498-c78359a01637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.3701,  0.2033,  0.0749,  0.6945,  0.3408, -0.2208, -0.1888,\n",
            "          -0.4437, -0.8898],\n",
            "         [-0.8997, -0.4243, -1.2301, -1.4120, -0.5841, -0.2921, -0.5119,\n",
            "           0.4848,  0.1416]],\n",
            "\n",
            "        [[ 0.0249, -0.6175, -1.0631, -0.2845,  0.3762,  0.1271,  0.1275,\n",
            "          -0.1636, -0.1190],\n",
            "         [-0.4074,  0.6277,  0.4570, -0.9860, -0.7779, -0.8869, -0.5556,\n",
            "          -0.3553, -0.6219]],\n",
            "\n",
            "        [[ 0.2446, -0.3100, -0.2781, -0.6828, -1.3511, -0.5244, -0.0429,\n",
            "          -0.3679, -0.6609],\n",
            "         [-0.4774, -0.1803, -0.4126,  0.9893,  0.6395, -0.4951, -0.3654,\n",
            "          -0.0406,  0.3745]]], grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Maxpool1d calcula el máximo valor para parches de un mapa de caracteristicas y reduce la dimensión de la señal de entrada\n",
        "m = MaxPool1d(6) #Recibe como parámetro el tamaño del kernel, y el tamaño del paso, que por defecto es igual al kernel\n",
        "input = torch.randn(2, 3, 8)\n",
        "print(input)\n",
        "output = m(input) ##El otput tiene el mismo nxm que el nxmxl del tensor de entrada pero la l se ve reducida (probablemente sea l+1-kernel si el tamaño del paso es 1)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCRX0Jtm8-uT",
        "outputId": "942c9bd9-c4b8-42a9-ad77-749137f7b84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.3216, -1.3050,  1.0142, -0.0575,  1.7287, -0.9887, -0.8285,\n",
            "           0.1806],\n",
            "         [-0.4318,  0.0492, -0.5692,  0.6922,  0.0933,  0.4473, -0.5662,\n",
            "           0.1734],\n",
            "         [ 0.8640, -0.3916,  0.0475,  0.8182, -0.7013,  0.2792,  1.0739,\n",
            "           0.9268]],\n",
            "\n",
            "        [[ 0.6347, -0.0437,  1.4699,  0.1867, -0.1432,  0.3252, -0.3472,\n",
            "           2.0984],\n",
            "         [-0.0979,  1.0013, -2.9121, -0.6872,  0.6046,  0.6919, -0.1856,\n",
            "          -1.7545],\n",
            "         [ 1.9661,  0.3951,  1.9198, -0.3303, -0.8137,  0.2590,  1.1249,\n",
            "          -1.4186]]])\n",
            "tensor([[[1.7287],\n",
            "         [0.6922],\n",
            "         [0.8640]],\n",
            "\n",
            "        [[1.4699],\n",
            "         [1.0013],\n",
            "         [1.9661]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = Embedding(10, 3) ##Crea una matriz de embedding con un vocabulario de tamaño 10 y una dimension de embedding 3\n",
        "input = torch.LongTensor([[9, 8, 7, 0,1], [6, 5, 4, 3,2]]) #Tensor de indices enteros\n",
        "embedding(input) ##Tensor tridimensional de forma (2,4,3) 2 pues es el tamaño del lote correspondiente al numero de secuencias de entrada, 4 porque es la long maxima de las secuencias de entrada y 3 porque es la dim especificada\n",
        "#Embedding es una matriz de muchos tensores, lo que hace es buscar en su tabla interna y devuelve los vectores de embedding correspondientes a los índices dados en el tensor es decir, para 2, ubica el tensor de dimension 3 con indice 2\n",
        "##Si indico un indice por fuera del vocabulario se peta (0,n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoTMHdK9tQVo",
        "outputId": "455c6e22-6c71-4b2d-84f2-f482db8b8f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4394,  0.7336,  0.3011],\n",
              "         [ 1.8582, -0.3632, -1.8076],\n",
              "         [-0.2005,  1.0626,  0.2678],\n",
              "         [-0.3113,  0.4633,  0.0996],\n",
              "         [ 0.4993, -0.4642, -0.4727]],\n",
              "\n",
              "        [[-0.7551,  0.5337, -0.0430],\n",
              "         [ 0.8066,  1.0297,  2.3186],\n",
              "         [ 1.0395, -1.1044,  1.4557],\n",
              "         [-0.2880,  0.6555, -0.7479],\n",
              "         [-0.1289, -2.0322, -0.1937]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Aplica ReLu :D al tensor de entrada\n",
        "m = ReLU()\n",
        "input = torch.randn(2,3,4)\n",
        "output = m(input)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygfJj0siAMSV",
        "outputId": "0cf6c2e4-3eb8-46cc-ccdb-4d2b00f34aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.5493, 0.2695, 0.0000, 2.0211],\n",
            "         [0.0000, 0.0000, 0.5249, 0.0000],\n",
            "         [0.4636, 0.0000, 0.0000, 1.5871]],\n",
            "\n",
            "        [[0.6233, 0.3285, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.2174],\n",
            "         [1.0785, 0.0000, 0.7890, 0.0000]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Es un contenedor secuencial, los modulos son aplicados en orden a la entrada\n",
        "model = Sequential(\n",
        "          Conv1d(2,1,3),\n",
        "          ReLU(),\n",
        "        ) ##Necesita una lista de modulos como parámetros\n",
        "\n",
        "input = torch.randn(3,2,4)\n",
        "output = model(input) ##Aplica primero conv1d al tensor de entrada y luego le pasa ReLU\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3mwPZS4AmQ-",
        "outputId": "ed454b76-6e63-4854-e963-8dd0cc8b327e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0000, 0.0000]],\n",
            "\n",
            "        [[0.0000, 0.3855]],\n",
            "\n",
            "        [[0.7444, 0.0000]]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Aplica una normalización Batch sobre un input 2d o 3d\n",
        "m = BN(3) ##Recibe como parametro el numero de caracteristicas o canales del input\n",
        "input = torch.randn(3, 3) ##Tensor random 2d\n",
        "\n",
        "output = m(input)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBVPavADCR_A",
        "outputId": "163227ef-650c-4158-c07a-a3933596de4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.1275,  1.1483,  1.2858],\n",
            "        [-1.3030, -1.2890, -1.1527],\n",
            "        [ 0.1755,  0.1408, -0.1331]], grad_fn=<NativeBatchNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Para acceder más facilmente a las funciones de convolución, de pooling, de activación, de pérdida, etc...\n",
        "##Son distintas a las usadas antes, tienen diferentes parámetros\n",
        "##Ejemplo\n",
        "input = torch.randn(3,2,4)\n",
        "filtros= torch.randn(3,2,4)\n",
        "function=F.conv1d(input,filtros) ##Recibe como entrada el input, y los filtros de forma\n",
        "print(function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN3YkY6RDKVK",
        "outputId": "5f8a849a-7061-45b5-ff49-7bc1f70297e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.1032],\n",
            "         [ 3.9813],\n",
            "         [-5.4659]],\n",
            "\n",
            "        [[-0.6133],\n",
            "         [-0.6724],\n",
            "         [ 2.7817]],\n",
            "\n",
            "        [[-3.5926],\n",
            "         [-0.3046],\n",
            "         [-2.0182]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BCEWithLogitsLoss\n",
        "target = torch.ones([2, 3], dtype=torch.float32)  # 64 classes, batch size = 10\n",
        "print(target)\n",
        "output = torch.full([2, 3], 1.5)  # A prediction (logit)\n",
        "print(output)\n",
        "pos_weight = torch.full([3],2.3)  # All weights are equal to 2.3\n",
        "print(pos_weight)\n",
        "loss = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "aplicado=loss(output, target)  # -log(sigmoid(1.5))\n",
        "print(aplicado.item()) #Escalar que indica el promedio de error de la predicción"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltuNQspxXW99",
        "outputId": "c1177812-7a6d-41b6-8491-718231bebc37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1.5000, 1.5000, 1.5000],\n",
            "        [1.5000, 1.5000, 1.5000]])\n",
            "tensor([2.3000, 2.3000, 2.3000])\n",
            "0.4632505476474762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DataLoader carga los datos de manera eficiente\n",
        "class MyIterableDataset(torch.utils.data.IterableDataset): #Clase para datasets que pueden ser iterados\n",
        "    def __init__(self, start, end): #Rango de numeros enteros que el dataset producirá\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "    def __iter__(self):\n",
        "        worker_info = torch.utils.data.get_worker_info() #devuelve diversa información útil del trabajador actual (incluida la identificación del trabajador, la réplica del conjunto de datos, la semilla inicial, etc.)\n",
        "        if worker_info is None:  # single-process data loading, return the full iterator\n",
        "            iter_start = self.start\n",
        "            iter_end = self.end\n",
        "        else:  # in a worker process\n",
        "            # split workload\n",
        "            per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers)))\n",
        "            worker_id = worker_info.id\n",
        "            iter_start = self.start + worker_id * per_worker\n",
        "            iter_end = min(iter_start + per_worker, self.end)\n",
        "        return iter(range(iter_start, iter_end))\n",
        "ds = MyIterableDataset(start=1, end=13) #Creamos una instancia de la clase con datos en [1,13)\n",
        "print(list(torch.utils.data.DataLoader(ds))) #Carga los datos utilizando un solo proceso\n",
        "dual_workers=torch.utils.data.DataLoader(ds, num_workers=6)\n",
        "print(list(dual_workers)) #carga los datos utilizando 2 subprocesos. Divide el rango [1, 13) entre los subprocesos (6)\n",
        "print(list(torch.utils.data.DataLoader(ds, num_workers=12))) #carga los datos utilizando 12 subprocesos. Divide el rango [1, 13) entre los subprocesos (12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPLLTjwmb5AX",
        "outputId": "6462145a-a656-412e-c58f-1b2a3c1e2276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([1]), tensor([2]), tensor([3]), tensor([4]), tensor([5]), tensor([6]), tensor([7]), tensor([8]), tensor([9]), tensor([10]), tensor([11]), tensor([12])]\n",
            "[tensor([1]), tensor([3]), tensor([5]), tensor([7]), tensor([9]), tensor([11]), tensor([2]), tensor([4]), tensor([6]), tensor([8]), tensor([10]), tensor([12])]\n",
            "[tensor([1]), tensor([2]), tensor([3]), tensor([4]), tensor([5]), tensor([6]), tensor([7]), tensor([8]), tensor([9]), tensor([10]), tensor([11]), tensor([12])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *TORCH-GEOMETRIC*"
      ],
      "metadata": {
        "id": "XrhoHClDkuho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as plt\n",
        "import networkx as nx\n",
        "from sklearn.manifold import TSNE\n",
        "from torch_geometric.utils import subgraph\n",
        "\n",
        "\n",
        "def visualize_graphExample(data):\n",
        "    G = to_networkx(data, to_undirected=True)  # Convertir a NetworkX Graph\n",
        "    nx.draw(G,node_size=5)\n",
        "    plt.pyplot.show()\n",
        "\n",
        "def get_reduced_data(data, num_nodes):\n",
        "    # Asegurarse de que num_nodes no sea mayor que el número total de nodos en el grafo original\n",
        "    assert num_nodes <= data.num_nodes, \"num_nodes should be less than or equal to the number of nodes in the original graph\"\n",
        "    # Seleccionar aleatoriamente algunos nodos\n",
        "    subset = torch.tensor(random.sample(data.edge_index[0].tolist(),num_nodes)) #Subset aleatorio\n",
        "    edge_index1,edge_attr1=subgraph(subset, edge_index=data.edge_index,relabel_nodes=True) #edge_index del subset aleatorio\n",
        "    #Creamos un nuevo subset sin nodos no conectados\n",
        "    subset2=(edge_index1[0].tolist()+edge_index1[1].tolist())\n",
        "    subset1 = []\n",
        "    for i in subset2:\n",
        "      if i not in subset1:\n",
        "        subset1.append(i)\n",
        "    edge_index1,edge_attr1=subgraph(torch.tensor(subset1), edge_index=edge_index1,relabel_nodes=True) #edge_index de los nodos aleatorios, sin los nodos dispersos\n",
        "    reduced_data = Data(edge_index=edge_index1,num_nodes=len(subset1)) #Creamos la nueva data reducida\n",
        "    return reduced_data\n",
        "\n",
        "#Usaremos un dataset pequeño de ejemplo de Planetoid (como Cora), que es una colección de datos de grafos comúnmente utilizada en la investigación de GCN\n",
        "# Descargamos el dataset de Cora\n",
        "datasetExample1 = Planetoid(root='data/Planetoid', name='Cora', transform=T.NormalizeFeatures()) #Usamos tambien una transformada del paquete de transformers\n",
        "\n",
        "# Obtenemos un solo grafo de ejemplo del dataset\n",
        "data = datasetExample1[0]\n",
        "num_nodes = 200 #Se puede cambiar para tener más o menos nodos\n",
        "dataReduced = get_reduced_data(data, num_nodes)\n",
        "visualize_graphExample(dataReduced) #Visualizamos el grafo antes de pasar por el modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNhAOsolqBlD",
        "outputId": "bf94f266-9f39-488d-cc58-ac12f131a0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "edge_index = torch.tensor([[0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6],\n",
        "                            [1, 0, 2, 1, 3, 2, 4, 3, 5, 4, 6, 5]])\n",
        "subset = torch.tensor([3, 4, 5])\n",
        "a,b=subgraph(subset, edge_index,relabel_nodes=True)\n",
        "print(a)\n",
        "reduced_data = Data(edge_index=a,num_nodes=3)\n",
        "print(reduced_data.num_nodes,reduced_data.num_edges)\n",
        "#print(reduced_data.node_stores)\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "G = to_networkx(reduced_data)\n",
        "labels = {}\n",
        "j=0\n",
        "for i in range(len(subset)):\n",
        "  labels[j] = subset[i].item()\n",
        "  j+=1\n",
        "print(G.nodes)\n",
        "nx.draw(G,labels=labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3UgwE0to_12",
        "outputId": "58da01eb-e539-4268-d466-14b54377082b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 1, 2],\n",
            "        [1, 0, 2, 1]])\n",
            "3 4\n",
            "[0, 1, 2]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Codigo principal**\n",
        "Debe ser corrido todo en orden para su correcto funcionamiento"
      ],
      "metadata": {
        "id": "bZArFX68LmCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Definición de modelos**"
      ],
      "metadata": {
        "id": "9FMJS7smdJMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entendamos primero como funcionan los modelos en PyTorch:\n",
        "Los modelos en pytorch se definen como clases hijas de la clase Módulo de pytorch, esto le permite heredar todos los métodos y atributos que se deinen en la documentación de la librería.\n",
        "Forward define la lógica del paso hacia adelante del modelo, es decir, como se procesan los datos de entrada para obtener la salida.\n",
        "En pytorch la función forward no se llama directamente. En su lugar, se llama la instancia del modelo como si fuera una función, lo que internamente llama a forward. Este mecanismo es posible porque la clase Module de PyTorch tiene un método __call__ sobrecargado que hace algunas tareas adicionales como manejar hooks, y luego llama a forward.\n",
        "\n",
        "**Detalles del paso Forward**:\n",
        "1. Entrada: Se suministran datos de entrada al modelo.\n",
        "\n",
        "2. Procesamiento: Cada capa del modelo aplica una transformación a los datos.\n",
        "Transformaciones comunes incluyen multiplicación matricial, funciones de activación (ReLU, Sigmoid), convoluciones, etc.\n",
        "3. Salida:El resultado final de las transformaciones es la predicción del modelo.\n",
        "\n",
        "**Detalles del Backward Pass:**\n",
        "\n",
        "1. Cálculo de la pérdida:Se calcula la pérdida (error) entre las predicciones del modelo y los valores verdaderos.\n",
        "\n",
        "2. Cálculo de gradientes: Se calculan los gradientes de la función de pérdida con respecto a cada parámetro del modelo usando el algoritmo de retropropagación.\n",
        "PyTorch realiza esto automáticamente si se llama a loss.backward(), se le puede especificar la función de pérdida deseada, lo veremos más adelante.\n",
        "\n",
        "3. Actualización de parámetros: Los gradientes calculados se usan para actualizar los parámetros del modelo.\n",
        "Esto es manejado por el optimizador (por ejemplo, SGD, Adam).\n",
        "\n",
        "**Resumen del Proceso Completo**\n",
        "1. Forward Pass:Los datos de entrada pasan a través de la red y se producen las predicciones.\n",
        "La lógica está definida en el método forward.\n",
        "\n",
        "2. Cálculo de Pérdida:Se compara la predicción con el valor verdadero para calcular la pérdida.\n",
        "\n",
        "3. Backward Pass:Se calculan los gradientes de la pérdida con respecto a los parámetros del modelo.\n",
        "PyTorch realiza esto mediante loss.backward().\n",
        "4. Actualización de Parámetros:Los parámetros del modelo se actualizan usando los gradientes calculados.\n",
        "Esto es manejado por el optimizador con optimizer.step().\n",
        "\n",
        "Este ciclo de forward y backward se repite para cada batch de datos durante el entrenamiento del modelo, permitiendo que el modelo aprenda a partir de los datos y mejore sus predicciones.\n",
        "\n",
        "El paso forward va descrito como un método dentro de la misma clase del modelo, mientras que el paso backward se ve en el código principal."
      ],
      "metadata": {
        "id": "ZXcHfXeoOrZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clases hijas de la clase Modulo, clase base para todos los modelos, heredan todas sus atributos y métodos\n",
        "class GCN(torch.nn.Module): #Implementación de un modelo de Red Neuronal Gráfica (Graph Neural Network, GNN) utilizando convoluciones de grafos (Graph Convolutions)\n",
        "    def __init__(self, hidden_channels, num_layers, max_z, train_dataset, use_feature=False, node_embedding=None, dropout=0.5):  #Constructor e inicialización de la clase\n",
        "        #hidden_channels: Número de canales ocultos para las capas GCN.\n",
        "        #num_layers: Número de capas GCN en la red.\n",
        "        #max_z: Tamaño máximo del embeding para z.\n",
        "        #train_dataset: Dataset de entrenamiento para extraer características y nodos.\n",
        "        #use_feature: Indica si se deben utilizar características adicionales de los nodos.\n",
        "        #node_embedding: Embedding opcional para nodos.\n",
        "        #dropout: Tasa de dropout (tecnica para reducir el sobreajuste) para regularización.\n",
        "        super(GCN, self).__init__()\n",
        "        self.use_feature = use_feature\n",
        "        self.node_embedding = node_embedding\n",
        "        self.max_z = max_z\n",
        "        self.z_embedding = Embedding(self.max_z, hidden_channels) #Embedding para las etiquetas de los nodos.\n",
        "\n",
        "        #Creación de las capas GCN\n",
        "        self.convs = ModuleList() #Modulelist con los modulos (capas) de convoluciones de grafos\n",
        "        initial_channels = hidden_channels #Determina el numero de canales para la primera capa\n",
        "        if self.use_feature: #Si se utilizan características de nodos (use_feature), se añaden al número de canales de entrada.\n",
        "            initial_channels += train_dataset.num_features\n",
        "        if self.node_embedding is not None: #Si se usa node_embedding, también se añaden estos canales.\n",
        "            initial_channels += node_embedding.embedding_dim\n",
        "        self.convs.append(GCNConv(initial_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.convs.append(GCNConv(hidden_channels, hidden_channels)) #GCNConv crea un numero previamente especificado de capas de convolución de grafos (Graph Convolutional Network, GCN) con hidden_channels nodos de entrada y hidden_channels nodos de salida\n",
        "                                                                          #GCNConv toma las caracteristicas de entrada de los nodos y las actualiza teniendo en cuenta las caracteristicas de los vecinos y conexiones\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.lin1 = Linear(hidden_channels, hidden_channels) #Mapea de hidden_channels a hidden_channels a travez de transformaciones lineales.\n",
        "        self.lin2 = Linear(hidden_channels, 1) #Mapea de hidden_channels a 1 (clasificación binaria) a travez de transformaciones lineales.\n",
        "\n",
        "    def reset_parameters(self): #Este método reinicia los parámetros de las capas convolucionales, es útil para reentrenar el modelo desde cero.\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, z, edge_index, batch, x=None, edge_weight=None, node_id=None): #Determina como deben fluir los datos a través del modelo durante el forward pass\n",
        "        z_emb = self.z_embedding(z) #z es una entrada de características, y self.z_embedding es una capa de embedding que convierte estas características en vectores densos de tamaño #hidden_channels.\n",
        "        if z_emb.ndim == 3:  # Si z_emb tiene 3 dimensiones, significa que z tiene múltiples etiquetas enteras por lo tanto se suman a lo largo de la dimensión de las etiquetas enteras.\n",
        "            z_emb = z_emb.sum(dim=1)\n",
        "        if self.use_feature and x is not None: #Si self.use_feature es True y x no es None se concatenan las características originales x con las características embeddeadas z_emb. De lo contrario, usar solo z_emb.\n",
        "            x = torch.cat([z_emb, x.to(torch.float)], 1) #Concatena la secuencia dada de tensores en la dimensión dada. Todos los tensores deben tener la misma forma\n",
        "        else:\n",
        "            x = z_emb\n",
        "        if self.node_embedding is not None and node_id is not None: #Si hay una capa de embedding de nodo (self.node_embedding) y node_id no es None, concatenar el embedding de nodo a x\n",
        "            n_emb = self.node_embedding(node_id)\n",
        "            x = torch.cat([x, n_emb], 1)\n",
        "        for conv in self.convs[:-1]: #Aquí se aplican todas las capas de convolución de grafo excepto la última. Después de cada convolución, aplicar una función de activación ReLU y luego una capa de dropout.\n",
        "            x = conv(x, edge_index, edge_weight)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, edge_index, edge_weight) #Aplica la última capa de convolución de grafo.\n",
        "        if True:  # center pooling #Las capas de pooling reducen la dimension espacial de los datos\n",
        "            _, center_indices = np.unique(batch.cpu().numpy(), return_index=True) #Encuentra los índices de los nodos centrales en cada subgrafo.\n",
        "            x_src = x[center_indices]\n",
        "            x_dst = x[center_indices + 1]\n",
        "            x = (x_src * x_dst) #multiplica las características de los nodos fuente y destino\n",
        "            x = F.relu(self.lin1(x)) #Pasa por una capa lineal definida al inicio y luego por una capa de activación relu\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training) #Pasa por un dropout que es una técnica de regularización para reducir el sobreajuste, omite neuronas aleatoriamente\n",
        "            x = self.lin2(x) # Finalmente pasa por la otra capa lineal definida al inicio.\n",
        "        else:  # sum pooling\n",
        "            x = global_add_pool(x, batch)\n",
        "            x = F.relu(self.lin1(x))\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "            x = self.lin2(x) #Alternativamente, si no se usa pooling central, se realizar un pooling global sumando las características de los nodos en cada subgrafo,\n",
        "                              #seguido por una capa lineal, ReLU, dropout y otra capa lineal.\n",
        "\n",
        "        return x #Retorna la variable que representa las caracteristicas de los nodos luego de pasar por diferentes capas del modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "lebTzmUEMrRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module): #Implementación de un modelo de Red Neuronal Gráfica (Graph Neural Network, GNN) utilizando convoluciones de grafos (Graph Convolutions)\n",
        "    def __init__(self, hidden_channels, num_layers, max_z, train_dataset=None,\n",
        "                 use_feature=False, node_embedding=None, dropout=0.5):\n",
        "        super(SAGE, self).__init__()\n",
        "        self.use_feature = use_feature\n",
        "        self.node_embedding = node_embedding\n",
        "        self.max_z = max_z\n",
        "        self.z_embedding = Embedding(self.max_z, hidden_channels)\n",
        "\n",
        "        self.convs = ModuleList()\n",
        "        initial_channels = hidden_channels\n",
        "        if self.use_feature:\n",
        "            initial_channels += train_dataset.num_features\n",
        "        if self.node_embedding is not None:\n",
        "            initial_channels += node_embedding.embedding_dim\n",
        "        self.convs.append(SAGEConv(initial_channels, hidden_channels)) #Es el único cambio respecto al anterior modelo, aplica un operador SAGEConv en lugar de un GCNConv\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels)) #SAGEConv crea un numero previamente especificado de capas de convolución de grafos SAGE con hidden_channels nodos de entrada y hidden_channels nodos de salida\n",
        "                                                                          #SAGEConv toma las caracteristicas de entrada de los nodos y las actualiza teniendo en cuenta las caracteristicas de los vecinos y conexiones\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, z, edge_index, batch, x=None, edge_weight=None, node_id=None):\n",
        "        z_emb = self.z_embedding(z)\n",
        "        if z_emb.ndim == 3:  # in case z has multiple integer labels\n",
        "            z_emb = z_emb.sum(dim=1)\n",
        "        if self.use_feature and x is not None:\n",
        "            x = torch.cat([z_emb, x.to(torch.float)], 1)\n",
        "        else:\n",
        "            x = z_emb\n",
        "        if self.node_embedding is not None and node_id is not None:\n",
        "            n_emb = self.node_embedding(node_id)\n",
        "            x = torch.cat([x, n_emb], 1)\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, edge_index)\n",
        "        if True:  # center pooling\n",
        "            _, center_indices = np.unique(batch.cpu().numpy(), return_index=True)\n",
        "            x_src = x[center_indices]\n",
        "            x_dst = x[center_indices + 1]\n",
        "            x = (x_src * x_dst)\n",
        "            x = F.relu(self.lin1(x))\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "            x = self.lin2(x)\n",
        "        else:  # sum pooling\n",
        "            x = global_add_pool(x, batch)\n",
        "            x = F.relu(self.lin1(x))\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "            x = self.lin2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7YNFR1qbWw8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diferencias entre SAGE y Conv:\n",
        "\n",
        "**Características principales de GCNConv:**\n",
        "\n",
        "*   Agregación Simétrica: GCNConv utiliza una operación de agregación simétrica donde se promedia (o se hace una suma ponderada) de las características de los vecinos de cada nodo.\n",
        "*   Normalización: La operación incluye una normalización de los valores de los vecinos basada en los grados de los nodos, lo que asegura que la escala de las características de los nodos se mantenga estable durante el entrenamiento.\n",
        "\n",
        "**Características principales de SAGEConv:**\n",
        "\n",
        "*   Agregación de Vecinos: SAGEConv también agrega información de los vecinos, pero permite diferentes estrategias de agregación, como mean, LSTM y pooling.\n",
        "*   Agregación Asimétrica: A diferencia de GCNConv, SAGEConv puede aplicar una combinación asimétrica de las características del nodo central y sus vecinos.\n",
        "*   Inductivo: GraphSAGE está diseñado para ser inductivo, lo que significa que puede generar representaciones para nodos que no estaban presentes durante el entrenamiento.\n",
        "\n",
        "**Comparación**\n",
        "*   GCNConv: Usa agregación simétrica con normalización basada en los grados de los nodos.\n",
        "*   SAGEConv: Permite diferentes estrategias de agregación (media, LSTM, pooling) y puede ser asimétrica.\n",
        "\n",
        "\n",
        "\n",
        "*   GCNConv: Tiende a ser más adecuado para problemas transductivos donde todo el grafo está disponible durante el entrenamiento.\n",
        "*   SAGEConv: Diseñado para ser inductivo, por lo que es más adecuado para escenarios donde se necesitan representar nodos no vistos durante el entrenamiento.\n",
        "\n",
        "\n",
        "*   GCNConv: Puede ser computacionalmente más simple debido a su normalización simétrica.\n",
        "*   SAGEConv: Puede ser más flexible y poderoso en términos de capacidad de representación, pero esto puede venir a costa de mayor complejidad computacional.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uFfCeGGoX9mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Una arquitectura de aprendizaje profundo de un extremo a otro para la clasificación de gráficos, AAAI-18\n",
        "class DGCNN(torch.nn.Module): #Deep Graph Convolutional Neural Network\n",
        "    def __init__(self, hidden_channels, num_layers, max_z, k=0.6, train_dataset=None, #Constructor de la clase. Sus parámetros son:\n",
        "                #hidden_channels: Número de canales ocultos en las capas GCNConv. (entero)\n",
        "                #num_layers: Número de capas de convolución de grafos.\n",
        "                #max_z: Máximo valor para el embebido de nodos.\n",
        "                #k: Parámetro relacionado con el tamaño de la convolución 1D.\n",
        "                #train_dataset: Dataset de entrenamiento utilizado para calcular k si es necesario.\n",
        "                #dynamic_train: Booleano para indicar si se utiliza un entrenamiento dinámico. Se refiere a un enfoque en el que ciertos aspectos del\n",
        "                               #entrenamiento se ajustan o modifican en función de las necesidades y el comportamiento observado durante el proceso de entrenamiento. En este caso se ve relacionado con la manera\n",
        "                               #en que se selecciona el valor de k, que determina el tamaño de la convolución 1D\n",
        "                #GNN: Tipo de capa de convolución de grafos a utilizar (por defecto es GCNConv).\n",
        "                #use_feature: Booleano para indicar si se utilizan características adicionales de los nodos.\n",
        "                #node_embedding: Embedding de nodos adicional (puede ser None).\n",
        "                 dynamic_train=False, GNN=GCNConv, use_feature=False,\n",
        "                 node_embedding=None):\n",
        "        super(DGCNN, self).__init__() #Llama al constructor de la clase base torch.nn.Module.\n",
        "\n",
        "        self.use_feature = use_feature\n",
        "        self.node_embedding = node_embedding #Inicializa con los parámetros dados\n",
        "\n",
        "        if k <= 1:  #Si k <= 1, se interpreta como un percentil (un valor entre 0 y 1) y se convierte a un número absoluto de nodos.\n",
        "            if train_dataset is None:\n",
        "                k = 30 #Si train_dataset es None, se asigna un valor fijo de 30 a k.\n",
        "            else:\n",
        "                if dynamic_train:\n",
        "                    sampled_train = train_dataset[:1000] #Si dynamic_train es True, se utiliza una muestra de los primeros 1000 grafos del dataset de entrenamiento para calcular k.\n",
        "                else:\n",
        "                    sampled_train = train_dataset #Si dynamic_train es False, se utiliza todo el dataset de entrenamiento para calcular k.\n",
        "                num_nodes = sorted([g.num_nodes for g in sampled_train]) #Se ordena la lista de número de nodos en los grafos del dataset.\n",
        "                k = num_nodes[int(math.ceil(k * len(num_nodes))) - 1] #Se selecciona el número de nodos correspondiente al percentil especificado por k.\n",
        "                k = max(10, k)  #El valor de k se determina en función del dataset de entrenamiento.\n",
        "        self.k = int(k) #La k de la clase se establece como el valor entero de la k calculada\n",
        "\n",
        "        self.max_z = max_z #Inicializa con los parámetros dados\n",
        "        self.z_embedding = Embedding(self.max_z, hidden_channels) #Crea un diccionario con max_z palabras de #hidden_channels de dimensión\n",
        "\n",
        "        self.convs = ModuleList() #Lista de capas convolucionales que se aplicaran\n",
        "        initial_channels = hidden_channels #Inicializa los canales iniciales como los canales ocultos pasados como parámetros, a continuacion se determinan el numero de canales de entrada para la primera capa de convolucion de grafos\n",
        "        if self.use_feature:\n",
        "            initial_channels += train_dataset.num_features #Suma el numero de caracteristicas de los nodos del dataset de entrenamiento si use_feature es True\n",
        "        if self.node_embedding is not None: #self.node_embedding es una matriz de embeddings de nodos que, si está definida, proporciona embeddings preentrenados para los nodos.\n",
        "            initial_channels += node_embedding.embedding_dim #Si no está vacía suma la dimensión de los embeddings al numero inicial de canales\n",
        "\n",
        "        self.convs.append(GNN(initial_channels, hidden_channels)) #Crea la primera capa de convolución de grafos en la lista de modulos convs con initial_channels canales de entrada y hidden_channels canales de salida\n",
        "        for i in range(0, num_layers-1):\n",
        "            self.convs.append(GNN(hidden_channels, hidden_channels)) #Crea las demás capas de convolución de grafos, pero ajusta el numero de canales de entrada a hidden channels  ya que es lo que la primera \"saca\"\n",
        "        self.convs.append(GNN(hidden_channels, 1)) #Crea la ultima capa de convolución de grafos con hidden_channels canales de entrada y solo un canal de salida\n",
        "\n",
        "        conv1d_channels = [16, 32] #Crea la lista que contiene la información de los numeros de canales para las convoluciones en 1d\n",
        "        total_latent_dim = hidden_channels * num_layers + 1 #Establece la dimension total latente como la multiplicación del numero de cnales ocultos y el numero de capas más 1\n",
        "        conv1d_kws = [total_latent_dim, 5] #Crea la lista que contiene el tamaño del kernel de convolución\n",
        "        self.conv1 = Conv1d(1, conv1d_channels[0], conv1d_kws[0], #Crea la primera capa de convolución, que tiene un canal de entrada, y 16 canales de salida, un tamaño de kernel de total_latent_dim y un stride de total_latent_dim\n",
        "                            conv1d_kws[0])\n",
        "        self.maxpool1d = MaxPool1d(2, 2) #Crea un pooling con un tamaño de kernel de 2 y un stride de 2\n",
        "        self.conv2 = Conv1d(conv1d_channels[0], conv1d_channels[1],\n",
        "                            conv1d_kws[1], 1) ##Crea la segunda capa convolucional de 1d con 16 canales de entrada, 32 canales de salida, un tamaño de kernel de 5 y un stride de 1\n",
        "        dense_dim = int((self.k - 2) / 2 + 1) #Inicializa la dimensión densa como el entero más cercano a (k-2)/2 +1\n",
        "        dense_dim = (dense_dim - conv1d_kws[1] + 1) * conv1d_channels[1] #Reasigna el valor a dense_dim teniendo en cuenta el valor anterior\n",
        "        self.lin1 = Linear(dense_dim, 128) #Crea la primera transformación lineal con dense_dim canales de entrada y 128 canales de salida\n",
        "        self.lin2 = Linear(128, 1) #Crea la segunda transformación lineal con 128 canales de entrada y 1 de salida\n",
        "\n",
        "    def forward(self, z, edge_index, batch, x=None, edge_weight=None, node_id=None): #En PyTorch, la función forward no se llama directamente. En su lugar, se llama a la instancia del\n",
        "                                                                                      #modelo como si fuera una función, lo que internamente llama a forward.\n",
        "                                                                                      #Este mecanismo es posible porque la clase Module de PyTorch, de la cual hereda DGCNN, tiene un\n",
        "                                                                                      ##método __call__ sobrecargado que hace algunas tareas adicionales (como manejar hooks) y luego llama a forward.\n",
        "        z_emb = self.z_embedding(z)\n",
        "        if z_emb.ndim == 3:\n",
        "            z_emb = z_emb.sum(dim=1) # en caso de que z tenga multiples etiquetas enteras se suman. Este trozo onvierte las etiquetas de los nodos z en embeddings.\n",
        "\n",
        "        if self.use_feature and x is not None:\n",
        "            x = torch.cat([z_emb, x.to(torch.float)], 1) ##Si use_feature es verdadero y se proporcionan características de nodos x, se concatenan las embeddings de las etiquetas con las características de los nodos.\n",
        "        else:\n",
        "            x = z_emb  #De lo contratio solo se usan los embeddings\n",
        "\n",
        "        if self.node_embedding is not None and node_id is not None:\n",
        "            n_emb = self.node_embedding(node_id)\n",
        "            x = torch.cat([x, n_emb], 1) #Si también se proporciona un embedding de nodos node_embedding y node_id, se concatenan estos embeddings con las características.\n",
        "        xs = [x] #Se crea una lista de tensores comenzando por el tensor x que contiene los embeddings, caracteristicas,etc...\n",
        "\n",
        "        for conv in self.convs:\n",
        "            xs += [torch.tanh(conv(xs[-1], edge_index, edge_weight))] #Se aplican las capas de convolución de gráficos definidas en self.convs. Cada capa toma la salida de la capa anterior\n",
        "                                                                      #y se aplica una función de activación, en este caso tanh. Las salidas de cada capa se almacenan en la lista xs.\n",
        "        x = torch.cat(xs[1:], dim=-1) #Realiza una concatenación de tensores a lo largo de una dimensión específica excluyendo el primer elemento, como la dimension es = -1, la concatenación se realiza a lo largo de\n",
        "                                      #la dimensión de caracteristicas\n",
        "\n",
        "        # Global pooling.\n",
        "        x = global_sort_pool(x, batch, self.k) #Utiliza global_sort_pool de la libreria pytorch_geometric.nn para transformar la matriz de nodos en unamatriz compacta para cada grafo\n",
        "        x = x.unsqueeze(1)  #Agrega una dimensión adicional para las capas convolucionales 1D\n",
        "        x = F.relu(self.conv1(x))#Aplica una capa convolucional seguida de una función de activación ReLU a las entradas.\n",
        "                                  #self.conv1 ss una capa convolucional definida en init. Esta capa toma una entrada x y aplica operaciones convolucionales para extraer características.\n",
        "                                  #La activación ReLU introduce no linealidad en el modelo, lo cual es crucial para que la red pueda aprender representaciones complejas.\n",
        "        x = self.maxpool1d(x) #Se reduce la dimensionalidad con la función MaxPool1D(2,2) de torch.nn\n",
        "        x = F.relu(self.conv2(x))#Se hace lo mismo que previamente, con una capa convolucional distinta\n",
        "        x = x.view(x.size(0), -1) #View devuelve un nuevo tensor con la misma información pero con un tamaño diferente, x.size(0) obtiene el tamaño de la primera dimensión,-1 es un comodín que le dice a PyTorch que\n",
        "                                  #calcule automáticamente esta dimensión para que el número total de elementos permanezca constante.\n",
        "\n",
        "        # MLP.\n",
        "        x = F.relu(self.lin1(x)) #Este fragmento aplica una capa lineal (definida en init) seguida de una función de activación ReLU a x.\n",
        "        x = F.dropout(x, p=0.5, training=self.training) #Se evita el sobreajuste con dropout\n",
        "        x = self.lin2(x) #Se aplica otra capa densa de clasificación definida tambien en init\n",
        "        return x"
      ],
      "metadata": {
        "id": "gwyJKZk3ZH1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DGCNN es una extensión de GCN, posee capacidades adicionales para manejar la selección dinámica de nodos y aplicación de convoluciones 1D para capturar patrones locales en los grafos.\n",
        "\n",
        "DGCNN incluye un mecanismo para seleccionar dinámicamente un número determinado de nodos (k) después de aplicar las capas de convolución GNN. Esto se hace mediante global_sort_pool, que ordena los nodos según sus características y selecciona los más relevantes. Este proceso permite al modelo centrarse en las partes más importantes del grafo, lo que puede ser útil para tareas en las que no todos los nodos son igualmente relevantes.\n",
        "\n",
        "Después del pooling global, DGCNN aplica convoluciones 1D (Conv1d) a las representaciones de los nodos. Esto ayuda a capturar patrones locales en las características de los nodos seleccionados. Las capas de convolución 1D se utilizan comúnmente en procesamiento de secuencias y señales, y aquí se adaptan para trabajar con las secuencias resultantes del pooling.\n",
        "\n",
        "DGCNN utiliza un enfoque de pooling global basado en el ordenamiento y selección de los nodos, lo que es diferente del pooling tradicional usado en otros modelos de grafos."
      ],
      "metadata": {
        "id": "rxaDrKwBaNAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GIN(torch.nn.Module): #Implementación de un modelo de Red Neuronal Gráfica GIN (Graph isomorphism operator) utilizando convoluciones de grafos\n",
        "    def __init__(self, hidden_channels, num_layers, max_z, train_dataset,\n",
        "                 use_feature=False, node_embedding=None, dropout=0.5,\n",
        "                 jk=True, train_eps=False):\n",
        "        super(GIN, self).__init__()\n",
        "        self.use_feature = use_feature\n",
        "        self.node_embedding = node_embedding\n",
        "        self.max_z = max_z\n",
        "        self.z_embedding = Embedding(self.max_z, hidden_channels)\n",
        "        self.jk = jk\n",
        "\n",
        "        initial_channels = hidden_channels\n",
        "        if self.use_feature:\n",
        "            initial_channels += train_dataset.num_features\n",
        "        if self.node_embedding is not None:\n",
        "            initial_channels += node_embedding.embedding_dim\n",
        "        self.conv1 = GINConv( #Define una capa que recibe como parámetro (obligatorio) una red neuronal que mapea la variable de caracteristicas de nodos x de forma [-1, in_channels] a la forma\n",
        "                                #[-1, out_channels], e.g., definida por torch.nn.Sequential. Esta capa consiste en un modulo secuencial de operaciones lineales, funciones de activación ReLU y normalización por lotes.\n",
        "            Sequential(\n",
        "                Linear(initial_channels, hidden_channels),\n",
        "                ReLU(),\n",
        "                Linear(hidden_channels, hidden_channels),\n",
        "                ReLU(),\n",
        "                BN(hidden_channels),\n",
        "            ),\n",
        "            train_eps=train_eps)\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for i in range(num_layers - 1):\n",
        "            self.convs.append(\n",
        "                GINConv( #Define ya no solo una sino un numero especificado previamente de capas GIN, estas capas de convolución se aplican de manera iterativa para\n",
        "                        #propagar las características de los nodos a través del grafo y aprender representaciones cada vez más abstractas.\n",
        "                    Sequential(\n",
        "                        Linear(hidden_channels, hidden_channels),\n",
        "                        ReLU(),\n",
        "                        Linear(hidden_channels, hidden_channels),\n",
        "                        ReLU(),\n",
        "                        BN(hidden_channels),\n",
        "                    ),\n",
        "                    train_eps=train_eps))\n",
        "\n",
        "        self.dropout = dropout\n",
        "        if self.jk:\n",
        "            self.lin1 = Linear(num_layers * hidden_channels, hidden_channels)\n",
        "        else:\n",
        "            self.lin1 = Linear(hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z, edge_index, batch, x=None, edge_weight=None, node_id=None):\n",
        "        z_emb = self.z_embedding(z)\n",
        "        if z_emb.ndim == 3:  # in case z has multiple integer labels\n",
        "            z_emb = z_emb.sum(dim=1)\n",
        "        if self.use_feature and x is not None:\n",
        "            x = torch.cat([z_emb, x.to(torch.float)], 1)\n",
        "        else:\n",
        "            x = z_emb\n",
        "        if self.node_embedding is not None and node_id is not None:\n",
        "            n_emb = self.node_embedding(node_id)\n",
        "            x = torch.cat([x, n_emb], 1)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        xs = [x]\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index)\n",
        "            xs += [x]\n",
        "        if self.jk:\n",
        "            x = global_mean_pool(torch.cat(xs, dim=1), batch)\n",
        "        else:\n",
        "            x = global_mean_pool(xs[-1], batch)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x\n",
        "#GIN es un modelo de Red Neuronal de grafos diseñado para aprender representaciones de nodos en grafos, sensible a la estructura del grafo\n",
        "#y capaz de manejar grafos con diferentes etiquetas de nodos y aristas. Utiliza convoluciones de grafos, pooling global y capas lineales\n",
        "#para realizar tareas como clasificación de grafos y predicción de enlaces."
      ],
      "metadata": {
        "id": "ONxsB-1Uaws-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Definición de utilidades**"
      ],
      "metadata": {
        "id": "8wObCgmydOJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neighbors(fringe, A, outgoing=True): #Encuentra todos los vecinos inmediatos de los nodos suministrados en una franja del grafo con matriz de adyacencia A. A es creada con scipy\n",
        "    # Si outgoing=True, encuentra vecinos con aristas que salen; ode otra forma, encuentra vecinos con aristas entrantes\n",
        "    if outgoing:\n",
        "        res = set(A[list(fringe)].indices)\n",
        "    else:\n",
        "        res = set(A[:, list(fringe)].indices)\n",
        "    return res"
      ],
      "metadata": {
        "id": "TmxCBU1KdaBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k-hop se refiere a la distancia entre nodos media en terminos de aristas o enlaces. Un k-hop indica todos los nodos que se pueden alcanzar desde un nodo fuente en k pasos o menos. Así, un 0-hop es el mismo nodo, un 1-hop son\n",
        "#inmediatamente a al nodo (vecinos directos)...\n",
        "def k_hop_subgraph(src, dst, num_hops, A, sample_ratio=1.0, #Extrae el k-hop que rodea el subgrafo alrededor del enlace (src,dst) de A, donde A es la matriz de adyacencia. num_hops es el numero de saltos a considerar.\n",
        "                   max_nodes_per_hop=None, node_features=None, ##sample_ratio es la proporción de nodos por salto a considerar (por defecto 1.0, es decir, todos), max_nodes_per_hop es el número máximo de nodos a incluir por salto.\n",
        "                   y=1, directed=False, A_csc=None): #node_features son las características de los nodos del grafo y y es la etiqueta del enlace\n",
        "    # Extract the k-hop enclosing subgraph around link (src, dst) from A.\n",
        "    #Extrae el subgrafo k-hop que rodea el enlace (fuente, destino)=>arista, desde A\n",
        "    nodes = [src, dst] #Lista de nodos iniciales que incluye a source y destiny\n",
        "    dists = [0, 0] #Lista de distancias\n",
        "    visited = set([src, dst]) #Conjunto de nodos visitados\n",
        "    fringe = set([src, dst]) #Conjunto de nodos en el limite de exploración\n",
        "    for dist in range(1, num_hops+1): #Itera sobre cada distancia, desde 1 hasta num_hops\n",
        "        if not directed:\n",
        "            fringe = neighbors(fringe, A) #Si el grafo no es dirigido actualiza fringe con los vecinos\n",
        "        else:\n",
        "            out_neighbors = neighbors(fringe, A)\n",
        "            in_neighbors = neighbors(fringe, A_csc, False)\n",
        "            fringe = out_neighbors.union(in_neighbors) #Si el grafo es dirigido actualiza fringe con los vecinos salientes unido a los vecinos entrantes\n",
        "        fringe = fringe - visited #Elimina los nodos ya visitados en fringe\n",
        "        visited = visited.union(fringe) #Actualiza visited con los nodos en fringe\n",
        "        if sample_ratio < 1.0:\n",
        "            fringe = random.sample(fringe, int(sample_ratio*len(fringe))) #Si sample_ratio es menor a 1.0, selecciona aleatoriamente una proporción de nodos en fringe.\n",
        "        if max_nodes_per_hop is not None:\n",
        "            if max_nodes_per_hop < len(fringe):\n",
        "                fringe = random.sample(fringe, max_nodes_per_hop) #Si max_nodes_per_hop está definido y es menor que el tamaño de fringe, selecciona aleatoriamente hasta max_nodes_per_hop nodos en fringe.\n",
        "        if len(fringe) == 0: #Si fringe está vacío, termina la iteración. Significa que llego al limite de nodos alcanzables en k-hops. Es como si se fuese propagando para saber cuales nodos se alcanzan en k-hops\n",
        "            break\n",
        "        nodes = nodes + list(fringe)\n",
        "        dists = dists + [dist] * len(fringe) #Añade los nodos en fringe a nodes y sus distancias correspondientes a dists.\n",
        "    subgraph = A[nodes, :][:, nodes] #Extrae el subgrafo de A que incluye solo los nodos seleccionados.\n",
        "\n",
        "    subgraph[0, 1] = 0\n",
        "    subgraph[1, 0] = 0 #Elimina el enlace original (src, dst) del subgrafo.\n",
        "\n",
        "    if node_features is not None:\n",
        "        node_features = node_features[nodes] #Si node_features está definido, extrae las características de los nodos seleccionados.\n",
        "\n",
        "    return nodes, subgraph, dists, node_features, y #Devuelve la lista de nodos del subgrafo, la submatriz que representa las conexiones del grafo, la lista de distancias, las caracteristicas de los nodos seleccionados y la etiquetas del enlace"
      ],
      "metadata": {
        "id": "_FD8oE2TeNGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drnl_node_labeling(adj, src, dst):\n",
        "    # Etiquetado de nodos de doble radio (DRNL). Técnica utilizada para asignar etiquetas a los nodos en un grafo basándose en su distancia a dos nodos específicos, src y dst\n",
        "    src, dst = (dst, src) if src > dst else (src, dst) #El código asume que src < dst. Si no es así, intercambia src y dst\n",
        "\n",
        "    idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
        "    adj_wo_src = adj[idx, :][:, idx]\n",
        "    idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
        "    adj_wo_dst = adj[idx, :][:, idx]\n",
        "    #Se eliminan los nodos src y dst del grafo respectivamente, creando dos versiones del grafo sin estos nodos: adj_wo_src y adj_wo_dst.\n",
        "\n",
        "    dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True, indices=src)\n",
        "    dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
        "    dist2src = torch.from_numpy(dist2src) #Se calcula la distancia más corta de todos los nodos al nodo src en el grafo adj_wo_src\n",
        "\n",
        "    dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True, indices=dst-1)\n",
        "    dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
        "    dist2dst = torch.from_numpy(dist2dst) #Se calcula la distancia más corta de todos los nodos al nodo dst en el grafo adj_wo_dst\n",
        "\n",
        "    dist = dist2src + dist2dst #Se calcula la suma de las distancias a src y dst, y se divide por 2 para obtener la distancia promedio.\n",
        "    dist_over_2, dist_mod_2 = dist // 2, dist % 2 #Se calcula el módulo de esta distancia con respecto a 2\n",
        "\n",
        "    z = 1 + torch.min(dist2src, dist2dst)\n",
        "    z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
        "    z[src] = 1.\n",
        "    z[dst] = 1.\n",
        "    z[torch.isnan(z)] = 0.\n",
        "    #Se asigna una etiqueta a cada nodo según una fórmula basada en estas distancias. Finalmente, se asignan etiquetas especiales a los nodos src y dst. Si alguna etiqueta resulta ser NaN, se asigna 0.\n",
        "\n",
        "    return z.to(torch.long) #El vector de etiquetas z se convierte al tipo de datos de tensor y se retorna.\n"
      ],
      "metadata": {
        "id": "0dq2QJ0bejNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def de_node_labeling(adj, src, dst, max_dist=3): #Codificación de distancia (Distance Encoding) para asignar etiquetas a los nodos en un grafo\n",
        "    src, dst = (dst, src) if src > dst else (src, dst)\n",
        "\n",
        "    dist = shortest_path(adj, directed=False, unweighted=True, indices=[src, dst]) #Se utiliza la función shortest_path para calcular la distancia más corta desde cada nodo en el grafo hasta los nodos src y dst.\n",
        "    dist = torch.from_numpy(dist) #La matriz resultante dist contiene las distancias de todos los nodos a src en la primera fila y las distancias a dst en la segunda fila.\n",
        "\n",
        "    dist[dist > max_dist] = max_dist #Se establece un límite superior max_dist para las distancias. Cualquier distancia mayor que max_dist (= 3 por defecto) se asigna como max_dist.\n",
        "    dist[torch.isnan(dist)] = max_dist + 1 #Si hay nodos que no están conectados a src o dst, la distancia se registra como NaN en la matriz. Estos valores NaN se reemplazan por max_dist + 1.\n",
        "\n",
        "    return dist.to(torch.long).t() #La matriz de distancias se convierte al tipo de datos de tensor y se transpone para que las distancias a src y dst estén en columnas separadas."
      ],
      "metadata": {
        "id": "BPxcJA-tgORl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def de_plus_node_labeling(adj, src, dst, max_dist=100): #Codigicación de distancia adicional. Cuando se computa la distancia al source, enmascara temporalmente el destino, y viceversa. Es en essencia lo mismo que el double radius node labeling\n",
        "    src, dst = (dst, src) if src > dst else (src, dst) # Asegura que src siempre sea menor que dst intercambiándolos si es necesario.\n",
        "\n",
        "    idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
        "    adj_wo_src = adj[idx, :][:, idx]\n",
        "\n",
        "    idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
        "    adj_wo_dst = adj[idx, :][:, idx]\n",
        "\n",
        "    dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True, indices=src) #Calcula la matriz de distancias desde cada nodo al nodo source\n",
        "    dist2src = np.insert(dist2src, dst, 0, axis=0) #Inserta 0 en la matriz dist2src en el indice del destino\n",
        "    dist2src = torch.from_numpy(dist2src) #Transformamos la matriz de distancias en un tensor\n",
        "\n",
        "    dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True, indices=dst-1) #Calcula la matriz de distancias desde cada nodo al nodo anterior a destino\n",
        "    dist2dst = np.insert(dist2dst, src, 0, axis=0) #Inserta 0 en la matriz dist2src en el indice del source\n",
        "    dist2dst = torch.from_numpy(dist2dst) #Transformamos la matriz de distancias en un tensor\n",
        "\n",
        "    dist = torch.cat([dist2src.view(-1, 1), dist2dst.view(-1, 1)], 1) #transforma los tensores en tensores \"columna\" de tamaño nxn y luego los concatena con cat (quedan dos columnas)\n",
        "    dist[dist > max_dist] = max_dist #Establece todas las distancias mayores que max_dist a max_dist. Esto evita que distancias excesivamente grandes afecten los cálculos\n",
        "    dist[torch.isnan(dist)] = max_dist + 1 #Reemplaza cualquier valor NaN en el tensor de distancias con max_dist + 1. Esto suele ocurrir para nodos que no están conectados a src o dst.\n",
        "\n",
        "    return dist.to(torch.long) #Convierte el tensor de distancias al tipo de datos torch.long (enteros largos). Luego transpone el tensor para que las distancias a src y dst estén en columnas separadas."
      ],
      "metadata": {
        "id": "LiCDpBBGIwtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_pyg_graph(node_ids, adj, dists, node_features, y, node_label='drnl'): #Construye un grafo de pytorch_geometric desde una matriz de adyacencia de scipy\n",
        "    # Construct a pytorch_geometric graph from a scipy csr adjacency matrix.\n",
        "    u, v, r = ssp.find(adj) #Utiliza scipy.sparse para encontrar las posiciones de los elementos no cero en la matriz de adyacencia. Esto retorna en u las filas de los elementos no cero, en v las columnas de\n",
        "                            #los elementos no cero y en r los valores de los elementos no 0\n",
        "    num_nodes = adj.shape[0] #Establece el numero de nodos a partir de la dimension de la matriz de adyacencia\n",
        "\n",
        "    node_ids = torch.LongTensor(node_ids) #Conviertte los id's de los nodos en un tensor de pytorch\n",
        "    u, v = torch.LongTensor(u), torch.LongTensor(v)\n",
        "    r = torch.LongTensor(r) #Convierte los u,v,r de los nodos en un tensor de pytorch\n",
        "    edge_index = torch.stack([u, v], 0) #Concatena u y v para representar las aristas del grafo\n",
        "    edge_weight = r.to(torch.float) #Establece el peso de cada arista como los valores  de cada elemento no 0 de la matriz de adyacencia\n",
        "    y = torch.tensor([y]) #y que representa la etiqueta del grafo se convierte en un tensor\n",
        "\n",
        "    #SE ETIQUETAN LOS NODOS CON DIFERENTEES TECNICAS DEPENDIENDO DE COMO SE LLAMA A LA FUNCIÓN, POR DEFECTO ESTÁ EN DOUBLE RADIUS NODE LABELING\n",
        "    if node_label == 'drnl':  # DRNL\n",
        "        z = drnl_node_labeling(adj, 0, 1)\n",
        "    elif node_label == 'hop':  # Numero de saltos, se usa la matriz de distancias calculada previeamente\n",
        "        z = torch.tensor(dists)\n",
        "    elif node_label == 'zo':  # zero-one labeling trick\n",
        "        z = (torch.tensor(dists)==0).to(torch.long)\n",
        "                              #Con ayuda de la matriz de distancias calculada previeamente se crea un tensor booleano donde cada elemento es True si la distancia correspondiente es igual a 0 y False en caso contrario.\n",
        "                              #Luego se transforma a un tensor de elementos long, si el elemento es True queda 1, si es False queda como 0\n",
        "    elif node_label == 'de':  # distance encoding\n",
        "        z = de_node_labeling(adj, 0, 1)\n",
        "    elif node_label == 'de+':\n",
        "        z = de_plus_node_labeling(adj, 0, 1)\n",
        "    elif node_label == 'degree':  # this is technically not a valid labeling trick\n",
        "        z = torch.tensor(adj.sum(axis=0)).squeeze(0)\n",
        "        z[z>100] = 100  # limit the maximum label to 100\n",
        "        #Usa el grado de los nodos, es decir, que tantas aristas conectan con el para definir un tensor. Establece z como el máximo de etiquetamiento, si alguna etiqueta lo supera, lo fija en 100\n",
        "    else:\n",
        "        z = torch.zeros(len(dists), dtype=torch.long) #Si no se especifica un tipo en entiquetado válido se hace un tensor de 0's del tamaño de la matriz de distancias\n",
        "    data = Data(node_features, edge_index, edge_weight=edge_weight, y=y, z=z,\n",
        "                node_id=node_ids, num_nodes=num_nodes) #El objeto data es un objeto de pytorch_geometric que contiene toda la inforamación de un determinado grafo\n",
        "    return data"
      ],
      "metadata": {
        "id": "-ErkpdxkQN92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_enclosing_subgraphs(link_index, A, x, y, num_hops, node_label='drnl',\n",
        "                                ratio_per_hop=1.0, max_nodes_per_hop=None,\n",
        "                                directed=False, A_csc=None): #list_index es un tensor que representa los enklaces del grafo,  A es la matriz de adyacencia, x tiene las caracteristicas de los nodos,\n",
        "                                                             #'y' contiene las etiquetas asociadas a los enlaces, num_hosps contiene el numero de saltos a considerar en el grafo,\n",
        "                                                             #node_label es el tipo de etiquetamiento que se le da al grafo (por dfecto DRNL), ratio_per_hop es la proporción de nodos a incluir por salto,\n",
        "                                                             #max_nodes_per_hop es el número máximo de nodos por salto, directed si el grafo es o no dirifido, una version opcional en formato csc de la matriz de adyacencia\n",
        "    data_list = [] #Crea una lista vacía para posteriormente añadir los subgrafos\n",
        "\n",
        "    for src, dst in tqdm(link_index.t().tolist()): #Itera sobre cada par de nodos source y destino en list_index(en formato lista y traspuesto(para que cada fila contenga un par(src,dst)))\n",
        "        tmp = k_hop_subgraph(src, dst, num_hops, A, ratio_per_hop, #Extrae un subgrafo centrado en el enlace de src,dst\n",
        "                             max_nodes_per_hop, node_features=x, y=y,\n",
        "                             directed=directed, A_csc=A_csc)\n",
        "        data = construct_pyg_graph(*tmp, node_label) #Construye un objeto data admitido por pytorch_geometric que contiene la información de cada subgrafo centrado en el enlace de src,dst\n",
        "        data_list.append(data) #Añade el subgrafo a la lista de data\n",
        "\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "WH76K8byVrEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_edge_split(dataset, fast_split=False, val_ratio=0.05, test_ratio=0.1): #La función do_edge_split se utiliza para dividir un conjunto de datos de grafos en subconjuntos de entrenamiento, validación y prueba\n",
        "#Recibe como parámetros el conjunto de datos (dataset) que contiene un grafo de enlaces, proporción de aristas para el conjunto de validación., y proporción de aristas para el conjunto de prueba\n",
        "    data = dataset[0] ##Extrae el primer elemento del conjunto de datos.\n",
        "    random.seed(234) #Fija las semillas aleatorias para reproducibilidad.\n",
        "    torch.manual_seed(234) ##Fija las semillas aleatorias para reproducibilidad.\n",
        "\n",
        "    if not fast_split: #Si fast_split es False, se usa train_test_split_edges para realizar la división completa desde las utilidades del modulo pytorch_geometric\n",
        "        data = train_test_split_edges(data, val_ratio, test_ratio) #Se usa train_test_split_edges para dividir el grafo.\n",
        "        edge_index, _ = add_self_loops(data.train_pos_edge_index) #Se añaden bucles propios (self-loops) a las aristas de entrenamiento.\n",
        "        data.train_neg_edge_index = negative_sampling( #Se generan aristas negativas para el entrenamiento usando negative_sampling.\n",
        "            edge_index, num_nodes=data.num_nodes,\n",
        "            num_neg_samples=data.train_pos_edge_index.size(1))\n",
        "    else: #Si fast_split es True, se realiza una división rápida manualmente.\n",
        "        num_nodes = data.num_nodes\n",
        "        row, col = data.edge_index #Se obtiene el número de nodos y se separan las aristas en filas (row) y columnas (col).\n",
        "\n",
        "        mask = row < col\n",
        "        row, col = row[mask], col[mask] #Se seleccionan solo las aristas de la parte superior triangular de la matriz de adyacencia.\n",
        "        n_v = int(math.floor(val_ratio * row.size(0)))\n",
        "        n_t = int(math.floor(test_ratio * row.size(0))) #Se calculan las cantidades de aristas para validación (n_v) y prueba (n_t).\n",
        "\n",
        "        perm = torch.randperm(row.size(0)) #Se permutan aleatoriamente las aristas.\n",
        "\n",
        "        row, col = row[perm], col[perm]\n",
        "        r, c = row[:n_v], col[:n_v]\n",
        "        data.val_pos_edge_index = torch.stack([r, c], dim=0)\n",
        "        r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]\n",
        "        data.test_pos_edge_index = torch.stack([r, c], dim=0)\n",
        "        r, c = row[n_v + n_t:], col[n_v + n_t:]\n",
        "        data.train_pos_edge_index = torch.stack([r, c], dim=0) #Se dividen las aristas permutadas en conjuntos de validación, prueba y entrenamiento.\n",
        "\n",
        "        neg_edge_index = negative_sampling(\n",
        "            data.edge_index, num_nodes=num_nodes,\n",
        "            num_neg_samples=row.size(0)) #Se generan aristas negativas para validación, prueba y entrenamiento usando negative_sampling.\n",
        "        data.val_neg_edge_index = neg_edge_index[:, :n_v]\n",
        "        data.test_neg_edge_index = neg_edge_index[:, n_v:n_v + n_t]\n",
        "        data.train_neg_edge_index = neg_edge_index[:, n_v + n_t:] #Se añaden las aristas negativas\n",
        "\n",
        "    split_edge = {'train': {}, 'valid': {}, 'test': {}} #Se inicializa un diccionario split_edge para almacenar las aristas divididas.\n",
        "    split_edge['train']['edge'] = data.train_pos_edge_index.t()\n",
        "    split_edge['train']['edge_neg'] = data.train_neg_edge_index.t()\n",
        "\n",
        "    split_edge['valid']['edge'] = data.val_pos_edge_index.t()\n",
        "    split_edge['valid']['edge_neg'] = data.val_neg_edge_index.t()\n",
        "\n",
        "    split_edge['test']['edge'] = data.test_pos_edge_index.t()\n",
        "    split_edge['test']['edge_neg'] = data.test_neg_edge_index.t() #Se asignan las aristas positivas y negativas de entrenamiento, validación y prueba al diccionario.\n",
        "    return split_edge #Se devuelve el diccionario split_edge.\n"
      ],
      "metadata": {
        "id": "7BOmX0UpdDv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos_neg_edges(split, split_edge, edge_index, num_nodes, percent=100): #Esta función se utiliza para obtener las aristas positivas y negativas a partir de los datos divididos (split_edge) y devolver una muestra de estas aristas.\n",
        "#Recibe como parámetros el conjunto de datos de interés (train,valid,test), el diccionario (split_edge) que contiene las aristas divididas, el tensor con las aristas del grafo, el numero de nodos y el porcentaje de aristas a muestrear\n",
        "    if 'edge' in split_edge['train']:\n",
        "        pos_edge = split_edge[split]['edge'].t() #Si el conjunto de datos contiene aristas, se asignan las aristas positivas a pos_edge y se transponen para obtener el formato correcto.\n",
        "\n",
        "        if 'edge_neg' in split_edge[split]:\n",
        "            neg_edge = split_edge[split]['edge_neg'].t() #Si existen aristas negativas pre-muestreadas, se asignan a neg_edge y se transponen.\n",
        "\n",
        "        else:\n",
        "            new_edge_index, _ = add_self_loops(edge_index)\n",
        "            neg_edge = negative_sampling(\n",
        "                new_edge_index, num_nodes=num_nodes,\n",
        "                num_neg_samples=pos_edge.size(1)) #Si no existen aristas negativas pre-muestreadas, se añaden bucles propios a las aristas originales y se generan aristas negativas usando negative_sampling.\n",
        "\n",
        "        np.random.seed(123) #Se fija la semilla aleatoria para reproducibilidad.\n",
        "        num_pos = pos_edge.size(1) #Se obtiene el número total de aristas positivas.\n",
        "        perm = np.random.permutation(num_pos)\n",
        "        perm = perm[:int(percent / 100 * num_pos)] #Se crea una permutación aleatoria de índices y se selecciona un subconjunto basado en el porcentaje especificado.\n",
        "        pos_edge = pos_edge[:, perm] #Se asignan las aristas positivas muestreadas a pos_edge.\n",
        "\n",
        "        np.random.seed(123)\n",
        "        num_neg = neg_edge.size(1)\n",
        "        perm = np.random.permutation(num_neg)\n",
        "        perm = perm[:int(percent / 100 * num_neg)]\n",
        "        neg_edge = neg_edge[:, perm] #Se hace lo mismo para las aristas negativas\n",
        "\n",
        "    elif 'source_node' in split_edge['train']:\n",
        "        source = split_edge[split]['source_node']\n",
        "        target = split_edge[split]['target_node']#Si el conjunto de datos contiene nodos fuente, se asignan los nodos fuente y destino a source y target, respectivamente.\n",
        "        if split == 'train':\n",
        "            target_neg = torch.randint(0, num_nodes, [target.size(0), 1],\n",
        "                                       dtype=torch.long) #Si el conjunto es de entrenamiento\n",
        "        else:\n",
        "            target_neg = split_edge[split]['target_node_neg'] #Para otros conjuntos, se usan las aristas negativas pre-muestreadas.\n",
        "\n",
        "        np.random.seed(123) #Se fija la semilla aleatoria.\n",
        "        num_source = source.size(0) #Se obtiene el número total de nodos fuente.\n",
        "        perm = np.random.permutation(num_source)\n",
        "        perm = perm[:int(percent / 100 * num_source)] #Se crea una permutación aleatoria de índices y se selecciona un subconjunto basado en el porcentaje especificado.\n",
        "        source, target, target_neg = source[perm], target[perm], target_neg[perm, :] #Se asignan los nodos fuente y destino muestreados a source, target y target_neg.\n",
        "        pos_edge = torch.stack([source, target]) #Se apilan source y target para obtener pos_edge.\n",
        "\n",
        "        neg_per_target = target_neg.size(1) #Se calcula el número de aristas negativas por destino.\n",
        "        neg_edge = torch.stack([source.repeat_interleave(neg_per_target),\n",
        "                                target_neg.view(-1)]) #Se repiten los nodos fuente y se apilan con los destinos negativos para obtener neg_edge.\n",
        "    return pos_edge, neg_edge #Se devuelven las aristas positivas (pos_edge) y negativas (neg_edge)."
      ],
      "metadata": {
        "id": "0ZhtF9LPgIVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definición de métricas usadas para evaluar la probabilidad de que exista una conexión (o enlace) entre dos nodos en un grafo basado en sus vecinos comunes u otras heurísticas relacionadas con la estructura de sus vecindarios.\n",
        "\n",
        "def CN(A, edge_index, batch_size=100000): #El puntaje de vecinos comunes entre dos nodos 𝑢 y 𝑣 es simplemente el número de vecinos que comparten.\n",
        "#La idea es que dos nodos que comparten muchos vecinos son más propensos a estar conectados.\n",
        "    # The Common Neighbor heuristic score.\n",
        "    link_loader = DataLoader(range(edge_index.size(1)), batch_size)\n",
        "    scores = []\n",
        "    for ind in tqdm(link_loader):\n",
        "        src, dst = edge_index[0, ind], edge_index[1, ind]\n",
        "        cur_scores = np.array(np.sum(A[src].multiply(A[dst]), 1)).flatten()\n",
        "        scores.append(cur_scores)\n",
        "    return torch.FloatTensor(np.concatenate(scores, 0)), edge_index\n",
        "\n",
        "\n",
        "def AA(A, edge_index, batch_size=100000): #Esta heurística da más peso a los vecinos comunes que tienen menos conexiones, bajo la premisa de que tener vecinos raros es más significativo.\n",
        "    # The Adamic-Adar heuristic score.\n",
        "    multiplier = 1 / np.log(A.sum(axis=0))\n",
        "    multiplier[np.isinf(multiplier)] = 0\n",
        "    A_ = A.multiply(multiplier).tocsr()\n",
        "    link_loader = DataLoader(range(edge_index.size(1)), batch_size)\n",
        "    scores = []\n",
        "    for ind in tqdm(link_loader):\n",
        "        src, dst = edge_index[0, ind], edge_index[1, ind]\n",
        "        cur_scores = np.array(np.sum(A[src].multiply(A_[dst]), 1)).flatten()\n",
        "        scores.append(cur_scores)\n",
        "    scores = np.concatenate(scores, 0)\n",
        "    return torch.FloatTensor(scores), edge_index\n"
      ],
      "metadata": {
        "id": "hpRd-dzJimUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#El código de la clase Logger está diseñado para registrar y mostrar resultados de múltiples ejecuciones de un experimento\n",
        "class Logger(object):\n",
        "    def __init__(self, runs, info=None):\n",
        "        self.info = info\n",
        "        self.results = [[] for _ in range(runs)]\n",
        "\n",
        "    def add_result(self, run, result):\n",
        "        assert len(result) == 2\n",
        "        assert run >= 0 and run < len(self.results)\n",
        "        self.results[run].append(result)\n",
        "\n",
        "    def print_statistics(self, run=None, f=sys.stdout):\n",
        "        if run is not None:\n",
        "            result = 100 * torch.tensor(self.results[run])\n",
        "            argmax = result[:, 0].argmax().item()\n",
        "            print(f'Run {run + 1:02d}:', file=f)\n",
        "            print(f'Highest Valid: {result[:, 0].max():.2f}', file=f)\n",
        "            print(f'Highest Eval Point: {argmax + 1}', file=f)\n",
        "            print(f'   Final Test: {result[argmax, 1]:.2f}', file=f)\n",
        "        else:\n",
        "            result = 100 * torch.tensor(self.results)\n",
        "\n",
        "            best_results = []\n",
        "            for r in result:\n",
        "                valid = r[:, 0].max().item()\n",
        "                test = r[r[:, 0].argmax(), 1].item()\n",
        "                best_results.append((valid, test))\n",
        "\n",
        "            best_result = torch.tensor(best_results)\n",
        "\n",
        "            print(f'All runs:', file=f)\n",
        "            r = best_result[:, 0]\n",
        "            print(f'Highest Valid: {r.mean():.2f} ± {r.std():.2f}', file=f)\n",
        "            r = best_result[:, 1]\n",
        "            print(f'   Final Test: {r.mean():.2f} ± {r.std():.2f}', file=f)"
      ],
      "metadata": {
        "id": "1BASEkJ2je2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Predicción de enlaces usando SEAL (Código principal)**"
      ],
      "metadata": {
        "id": "sSaPoNxdiA2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEALDataset(InMemoryDataset): #Clase que hereda de la clase base para datasets proporcionada por pytorch para que quepan adecuadamente en memoria\n",
        "    def __init__(self, root, data, split_edge, num_hops, percent=100, split='train',\n",
        "                 use_coalesce=False, node_label='drnl', ratio_per_hop=1.0,\n",
        "                 max_nodes_per_hop=None, directed=False): # Los parámetros incluyen la ruta raíz (root), los datos (data), el borde dividido (split_edge), el número de saltos (num_hops),\n",
        "                                                          #el porcentaje (percent), el tipo de división (split), el uso de coalescencia (use_coalesce), el etiquetado de nodos (node_label),\n",
        "                                                          #la proporción por salto (ratio_per_hop), el número máximo de nodos por salto (max_nodes_per_hop), y si el grafo es dirigido (directed).\n",
        "        self.data = data\n",
        "        self.split_edge = split_edge\n",
        "        self.num_hops = num_hops\n",
        "        self.percent = int(percent) if percent >= 1.0 else percent #Toma como un percentil si el valor está entre 0 y 1, de resto lo toma como el valor exacto de porcentaje\n",
        "        self.split = split\n",
        "        self.use_coalesce = use_coalesce\n",
        "        self.node_label = node_label\n",
        "        self.ratio_per_hop = ratio_per_hop\n",
        "        self.max_nodes_per_hop = max_nodes_per_hop\n",
        "        self.directed = directed\n",
        "        super(SEALDataset, self).__init__(root) #Esta línea llama al constructor de la clase base InMemoryDataset con el parámetro root.\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0]) #Esta línea carga los datos y los slices (segmentos) procesados desde un archivo.\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        if self.percent == 100:\n",
        "            name = 'SEAL_{}_data'.format(self.split)\n",
        "        else:\n",
        "            name = 'SEAL_{}_data_{}'.format(self.split, self.percent)\n",
        "        name += '.pt'\n",
        "        return [name] #Estas líneas generan el nombre del archivo donde se guardarán los datos procesados.\n",
        "\n",
        "    def process(self):\n",
        "        pos_edge, neg_edge = get_pos_neg_edges(self.split, self.split_edge,  #Llama a la función definida en la parte de utilidades para obtener las aristas negativas y positivas a partir de los datos divididos\n",
        "                                               self.data.edge_index,\n",
        "                                               self.data.num_nodes,\n",
        "                                               self.percent)\n",
        "\n",
        "        if self.use_coalesce:  # Si es True comprime las aristas distintas entre los mismos dos nodos en una sola con peso\n",
        "            self.data.edge_index, self.data.edge_weight = coalesce(\n",
        "                self.data.edge_index, self.data.edge_weight,\n",
        "                self.data.num_nodes, self.data.num_nodes)\n",
        "\n",
        "        if 'edge_weight' in self.data:\n",
        "            edge_weight = self.data.edge_weight.view(-1) #Si self.data tiene un atributo edge_weight, se usa\n",
        "        else:\n",
        "            edge_weight = torch.ones(self.data.edge_index.size(1), dtype=int) #; de lo contrario, se asigna un peso de 1 a todos las aristas.\n",
        "        A = ssp.csr_matrix(\n",
        "            (edge_weight, (self.data.edge_index[0], self.data.edge_index[1])),\n",
        "            shape=(self.data.num_nodes, self.data.num_nodes) #Creación de la matriz de adyacencia con ayuda de scipy\n",
        "        )\n",
        "\n",
        "        if self.directed: #Si el grafo es dirigido (self.directed=True), se convierte A a formato CSC\n",
        "            A_csc = A.tocsc()\n",
        "        else:\n",
        "            A_csc = None\n",
        "\n",
        "        # Extract enclosing subgraphs for pos and neg edges\n",
        "        pos_list = extract_enclosing_subgraphs(\n",
        "            pos_edge, A, self.data.x, 1, self.num_hops, self.node_label,\n",
        "            self.ratio_per_hop, self.max_nodes_per_hop, self.directed, A_csc) #Se extraen subgrafos envolventes para las aristas positivas utilizando la función extract_enclosing_subgraphs con los parámetros especificados.\n",
        "        neg_list = extract_enclosing_subgraphs(\n",
        "            neg_edge, A, self.data.x, 0, self.num_hops, self.node_label,\n",
        "            self.ratio_per_hop, self.max_nodes_per_hop, self.directed, A_csc) #Similar a los subgrafos positivos, pero para las aristas negativas.\n",
        "\n",
        "        torch.save(self.collate(pos_list + neg_list), self.processed_paths[0]) #Se guardan los subgrafos positivos y negativos combinados en un archivo especificado en self.processed_paths[0].\n",
        "        del pos_list, neg_list #Se eliminan las listas pos_list y neg_list para liberar memoria."
      ],
      "metadata": {
        "id": "o1lFE4Z9NiE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SEALDynamicDataset(Dataset): #Hereda de la clase Dataset provista por torch_geometric\n",
        "    def __init__(self, root, data, split_edge, num_hops, percent=100, split='train',\n",
        "                 use_coalesce=False, node_label='drnl', ratio_per_hop=1.0,\n",
        "                 max_nodes_per_hop=None, directed=False, **kwargs): #Los parámetros incluyen la ruta raíz (root), los datos (data), el borde dividido (split_edge), el número de saltos (num_hops),\n",
        "                                                                    #el porcentaje (percent), el tipo de división (split), el uso de coalescencia (use_coalesce), el etiquetado de nodos (node_label),\n",
        "                                                                    #la proporción por salto (ratio_per_hop), el número máximo de nodos por salto (max_nodes_per_hop), y si el grafo es dirigido (directed).\n",
        "        self.data = data\n",
        "        self.split_edge = split_edge\n",
        "        self.num_hops = num_hops\n",
        "        self.percent = percent\n",
        "        self.use_coalesce = use_coalesce\n",
        "        self.node_label = node_label\n",
        "        self.ratio_per_hop = ratio_per_hop\n",
        "        self.max_nodes_per_hop = max_nodes_per_hop\n",
        "        self.directed = directed\n",
        "        super(SEALDynamicDataset, self).__init__(root) #Esta línea llama al constructor de la clase base Dataset con el parámetro root.\n",
        "\n",
        "        pos_edge, neg_edge = get_pos_neg_edges(split, self.split_edge,\n",
        "                                               self.data.edge_index,\n",
        "                                               self.data.num_nodes,\n",
        "                                               self.percent) #Llama a la función definida en la parte de utilidades para obtener las aristas negativas y positivas a partir de los datos divididos\n",
        "        self.links = torch.cat([pos_edge, neg_edge], 1).t().tolist() #Se concatenan los bordes positivos y negativos a lo largo de la dimensión 1, se transpone y se convierte a una lista de listas.\n",
        "        self.labels = [1] * pos_edge.size(1) + [0] * neg_edge.size(1) #Se crean etiquetas para los bordes, asignando 1 a los bordes positivos y 0 a los negativos.\n",
        "\n",
        "        if self.use_coalesce:  # Si es True comprime las aristas distintas entre los mismos dos nodos en una sola con peso\n",
        "            self.data.edge_index, self.data.edge_weight = coalesce(\n",
        "                self.data.edge_index, self.data.edge_weight,\n",
        "                self.data.num_nodes, self.data.num_nodes)\n",
        "\n",
        "        if 'edge_weight' in self.data:\n",
        "            edge_weight = self.data.edge_weight.view(-1)  #Si self.data tiene un atributo edge_weight, se usa;\n",
        "        else:\n",
        "            edge_weight = torch.ones(self.data.edge_index.size(1), dtype=int) #Se inicializa el tensor de pesos con 1 en cada uno\n",
        "        self.A = ssp.csr_matrix(\n",
        "            (edge_weight, (self.data.edge_index[0], self.data.edge_index[1])),\n",
        "            shape=(self.data.num_nodes, self.data.num_nodes) # de lo contrario, se asigna un peso de 1 a todos los bordes.\n",
        "        )\n",
        "        if self.directed:\n",
        "            self.A_csc = self.A.tocsc() #Se construye una matriz de adyacencia dispersa en formato CSR\n",
        "        else:\n",
        "            self.A_csc = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.links) #Este método devuelve el número de enlaces (bordes) en el dataset.\n",
        "\n",
        "    def len(self):\n",
        "        return self.__len__() #Este método es un \"alias\" para __len__, lo que proporciona una forma alternativa de obtener la longitud del dataset.\n",
        "\n",
        "    def get(self, idx): #Este método obtiene los datos de un índice específico (idx).\n",
        "        src, dst = self.links[idx] #Estas líneas extraen los nodos fuente (src) y destino (dst) del enlace en el índice idx\n",
        "        y = self.labels[idx] #, así como la etiqueta y correspondiente (1 para bordes positivos, 0 para negativos)\n",
        "        tmp = k_hop_subgraph(src, dst, self.num_hops, self.A, self.ratio_per_hop,\n",
        "                             self.max_nodes_per_hop, node_features=self.data.x,\n",
        "                             y=y, directed=self.directed, A_csc=self.A_csc) #Esta línea extrae un subgrafo de k saltos alrededor del enlace (src,dst)\n",
        "        data = construct_pyg_graph(*tmp, self.node_label) #Construye un grafo en el formato usado por PyTorch Geometric (PyG) a partir del subgrafo extraído y las etiquetas de los nodos\n",
        "\n",
        "        return data"
      ],
      "metadata": {
        "id": "dBg45wnAUMwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los anteriores fragmentos de código proporcionan una manera flexible de manejar los datasets de grafos, sin embargo SEALDataset procesa y almacena todos los datos en memoria después de la carga inicial, mientras que SEALDynamicDataset procesa los datos de manera dinámica, es decir, bajo demanda cuando se accede a ellos, en lugar de procesar todo de antemano y almacenarlo en memoria."
      ],
      "metadata": {
        "id": "D6fSjvgMXkK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(): #Define la función train sin argumentos\n",
        "    model.train() #Pone el modelo en modo entrenamiento, esto sale de la clase base de torch de la que heredan los modelos escritos en la parte de modelos\n",
        "\n",
        "    total_loss = 0 #Se inicializa la pérdida en 0\n",
        "    pbar = tqdm(train_loader, ncols=70) #Inicializa una barra de progreso usando tqdm para iterar sobre el train_loader. train_loader es un iterador sobre\n",
        "                                        #los datos de entrenamiento, y ncols=70 establece el ancho de la barra de progreso en 70 columnas en la consola.\n",
        "    for data in pbar: #Inicia un bucle que iterará sobre cada mini-batch en el train_loader. data contiene el mini-batch actual de datos de entrenamiento.\n",
        "        data = data.to(device) #Transfiere el mini-batch actual a la device (CPU o GPU) para asegurar que todos los datos se encuentren en el dispositivo correcto para el procesamiento.\n",
        "        optimizer.zero_grad() #Limpia los gradientes acumulados de la pasada anterior.\n",
        "        x = data.x if args.use_feature else None #Si args.use_feature es verdadero, asigna las características del nodo data.x a x. De lo contrario, x será None.\n",
        "        edge_weight = data.edge_weight if args.use_edge_weight else None #Si args.use_edge_weight es verdadero, asigna los pesos de las aristas data.edge_weight a edge_weight. De lo contrario, edge_weight será None.\n",
        "        node_id = data.node_id if emb else None #Si emb es verdadero, asigna los IDs de los nodos data.node_id a node_id. De lo contrario, node_id será None.\n",
        "        logits = model(data.z, data.edge_index, data.batch, x, edge_weight, node_id) #Aplica el forward definido en el modelo para los datos del lote en particular del ciclo a trabajar\n",
        "        loss = BCEWithLogitsLoss()(logits.view(-1), data.y.to(torch.float)) #Calcula la perdida del modelo con la función. Esta pérdida combina la función sigmoide y la función de pérdida BCE (Binary Cross Entropy)\n",
        "        loss.backward() #Calcula los gradientes para cada parámetro x que tiene requires_grad=True. Estos se acumulan x.grad para cada parámetro x.\n",
        "        optimizer.step() #Actualiza el valor de los parámetros del modelo basados en los gradientes calculados arriba. Utiliza el algoritmo Adam provisto por torch para optimizar\n",
        "        total_loss += loss.item() * data.num_graphs #CSe agrega la pérdida actual, multiplicada por el número de gráficos en el lote a la pérdida total\n",
        "\n",
        "    return total_loss / len(train_dataset) #Se devuelve la pérdida total promediada sobre el tamaño del conjunto de datos de entrenamiento. Esto proporciona una medida promedio de la pérdida por grafo"
      ],
      "metadata": {
        "id": "K9FWdY95ZMKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval() #Pone el modelo en modo evaluador\n",
        "\n",
        "    y_pred, y_true = [], [] #Se inicializan listas vacías para almacenar las predicciones (y_pred) y las etiquetas verdaderas (y_true).\n",
        "    for data in tqdm(val_loader, ncols=70): #Se inicia un bucle sobre los lotes de datos de validación (val_loader) con una barra de progreso (tqdm) para visualizar el progreso.\n",
        "        data = data.to(device) #Se mueven los datos a la GPU (device) si está disponible, de lo contrario, los datos se mantienen en la CPU.\n",
        "        x = data.x if args.use_feature else None #Asigna las caracteristicas de los datos a la variable x si args.use_feature es True\n",
        "        edge_weight = data.edge_weight if args.use_edge_weight else None #Asigna los pesos de las aristas a la variable si args.use_edge_weight es True\n",
        "        node_id = data.node_id if emb else None #Asigna el identificador de los nodos a la variable si emb es True\n",
        "        logits = model(data.z, data.edge_index, data.batch, x, edge_weight, node_id) #Se pasan los datos al modelo para obtener los logits (salida antes de aplicar la función de activación) del modelo.\n",
        "        y_pred.append(logits.view(-1).cpu()) #Se añaden las predicciones al final de la lista y_pred. Se utiliza view(-1) para aplanar los logits y cpu() para mover los tensores de la GPU a la CPU.\n",
        "        y_true.append(data.y.view(-1).cpu().to(torch.float)) #Se añaden las etiquetas verdaderas al final de la lista y_true. Se utiliza view(-1) para aplanar las etiquetas y cpu() para mover los tensores de la GPU a la CPU\n",
        "    val_pred, val_true = torch.cat(y_pred), torch.cat(y_true) #Se concatenan todas las predicciones y etiquetas verdaderas en un solo tensor para el conjunto de datos de validación.\n",
        "    pos_val_pred = val_pred[val_true==1] #Se seleccionan las predicciones correspondientes a ejemplos positivos en el conjunto de datos de validación.\n",
        "    neg_val_pred = val_pred[val_true==0] #Se seleccionan las predicciones correspondientes a ejemplos negativos en el conjunto de datos de validación.\n",
        "\n",
        "    y_pred, y_true = [], []\n",
        "    for data in tqdm(test_loader, ncols=70): ##Se inicia un bucle sobre los lotes de datos de testeo (test_loader) con una barra de progreso (tqdm) para visualizar el progreso.\n",
        "        data = data.to(device)\n",
        "        x = data.x if args.use_feature else None\n",
        "        edge_weight = data.edge_weight if args.use_edge_weight else None\n",
        "        node_id = data.node_id if emb else None\n",
        "        logits = model(data.z, data.edge_index, data.batch, x, edge_weight, node_id)\n",
        "        y_pred.append(logits.view(-1).cpu())\n",
        "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
        "    test_pred, test_true = torch.cat(y_pred), torch.cat(y_true)\n",
        "    pos_test_pred = test_pred[test_true==1]\n",
        "    neg_test_pred = test_pred[test_true==0] #De resto se hace lo mismo que arriba guardandolo a variables distintas\n",
        "\n",
        "    if args.eval_metric == 'hits': #Los resultados se evaluan con distintas métricas de evaluación de rendimiento del modelo\n",
        "        results = evaluate_hits(pos_val_pred, neg_val_pred, pos_test_pred, neg_test_pred)\n",
        "    elif args.eval_metric == 'mrr':\n",
        "        results = evaluate_mrr(pos_val_pred, neg_val_pred, pos_test_pred, neg_test_pred)\n",
        "    elif args.eval_metric == 'rocauc':\n",
        "        results = evaluate_ogb_rocauc(pos_val_pred, neg_val_pred, pos_test_pred, neg_test_pred)\n",
        "    elif args.eval_metric == 'auc':\n",
        "        results = evaluate_auc(val_pred, val_true, test_pred, test_true)\n",
        "\n",
        "    return results #Se devuelven los resultados"
      ],
      "metadata": {
        "id": "SArKHuZJZRsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definición de las métricas de evaluación\n",
        "def evaluate_hits(pos_val_pred, neg_val_pred, pos_test_pred, neg_test_pred):\n",
        "    results = {}\n",
        "    for K in [20, 50, 100]:\n",
        "        evaluator.K = K\n",
        "        valid_hits = evaluator.eval({\n",
        "            'y_pred_pos': pos_val_pred,\n",
        "            'y_pred_neg': neg_val_pred,\n",
        "        })[f'hits@{K}']\n",
        "        test_hits = evaluator.eval({\n",
        "            'y_pred_pos': pos_test_pred,\n",
        "            'y_pred_neg': neg_test_pred,\n",
        "        })[f'hits@{K}']\n",
        "\n",
        "        results[f'Hits@{K}'] = (valid_hits, test_hits)\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate_mrr(pos_val_pred, neg_val_pred, pos_test_pred, neg_test_pred):\n",
        "    neg_val_pred = neg_val_pred.view(pos_val_pred.shape[0], -1)\n",
        "    neg_test_pred = neg_test_pred.view(pos_test_pred.shape[0], -1)\n",
        "    results = {}\n",
        "    valid_mrr = evaluator.eval({\n",
        "        'y_pred_pos': pos_val_pred,\n",
        "        'y_pred_neg': neg_val_pred,\n",
        "    })['mrr_list'].mean().item()\n",
        "\n",
        "    test_mrr = evaluator.eval({\n",
        "        'y_pred_pos': pos_test_pred,\n",
        "        'y_pred_neg': neg_test_pred,\n",
        "    })['mrr_list'].mean().item()\n",
        "\n",
        "    results['MRR'] = (valid_mrr, test_mrr)\n",
        "    return results\n",
        "\n",
        "\n",
        "def evaluate_auc(val_pred, val_true, test_pred, test_true):\n",
        "    valid_auc = roc_auc_score(val_true, val_pred)\n",
        "    test_auc = roc_auc_score(test_true, test_pred)\n",
        "    results = {}\n",
        "    results['AUC'] = (valid_auc, test_auc)\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate_ogb_rocauc(pos_val_pred, neg_val_pred, pos_test_pred, neg_test_pred):\n",
        "    valid_rocauc = evaluator.eval({\n",
        "        'y_pred_pos': pos_val_pred,\n",
        "        'y_pred_neg': neg_val_pred,\n",
        "        })[f'rocauc']\n",
        "\n",
        "    test_rocauc = evaluator.eval({\n",
        "            'y_pred_pos': pos_test_pred,\n",
        "            'y_pred_neg': neg_test_pred,\n",
        "        })[f'rocauc']\n",
        "\n",
        "    results = {}\n",
        "    results['rocauc'] = (valid_rocauc, test_rocauc)\n",
        "    return results"
      ],
      "metadata": {
        "id": "MZOWRuRliy9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se ajustan los datos de configuración\n",
        "class Args:\n",
        "    dataset = 'actor' #'ogbl-collab' es la usada por defecto\n",
        "    fast_split = False\n",
        "    model = 'DGCNN'\n",
        "    sortpool_k = 0.6\n",
        "    num_layers = 5\n",
        "    hidden_channels = 32\n",
        "    batch_size = 32\n",
        "    num_hops = 1\n",
        "    ratio_per_hop = 1.0\n",
        "    max_nodes_per_hop = None\n",
        "    node_label = 'drnl'\n",
        "    use_feature = False\n",
        "    use_edge_weight = False\n",
        "    lr = 0.0001\n",
        "    epochs = 50\n",
        "    runs = 1\n",
        "    train_percent = 50\n",
        "    val_percent = 20\n",
        "    test_percent = 30\n",
        "    dynamic_train = False\n",
        "    dynamic_val = False\n",
        "    dynamic_test = False\n",
        "    num_workers = 16\n",
        "    train_node_embedding = False\n",
        "    pretrained_node_embedding = None\n",
        "    use_valedges_as_input = False\n",
        "    eval_steps = 1\n",
        "    log_steps = 1\n",
        "    data_appendix = ''\n",
        "    save_appendix = ''\n",
        "    keep_old = False\n",
        "    continue_from = None\n",
        "    only_test = False\n",
        "    test_multiple_models = False\n",
        "    use_heuristic = False\n",
        "\n",
        "args = Args()\n",
        "\n",
        "if args.save_appendix == '':\n",
        "    args.save_appendix = '_' + time.strftime(\"%Y%m%d%H%M%S\")\n",
        "if args.data_appendix == '':\n",
        "    args.data_appendix = '_h{}_{}_rph{}'.format(\n",
        "        args.num_hops, args.node_label, ''.join(str(args.ratio_per_hop).split('.')))\n",
        "    if args.max_nodes_per_hop is not None:\n",
        "        args.data_appendix += '_mnph{}'.format(args.max_nodes_per_hop)\n",
        "    if args.use_valedges_as_input:\n",
        "        args.data_appendix += '_uvai'\n",
        "\n",
        "args.res_dir = os.path.join('results/{}{}'.format(args.dataset, args.save_appendix))\n",
        "print('Results will be saved in ' + args.res_dir)\n",
        "if not os.path.exists(args.res_dir):\n",
        "    os.makedirs(args.res_dir)\n",
        "##NO HAREMOS UN BACKUP DE LOS RESULTADOS\n",
        "#if not args.keep_old:\n",
        "    # Backup python files.\n",
        "#    copy('seal_link_pred.py', args.res_dir)\n",
        "#    copy('utils.py', args.res_dir)\n",
        "log_file = os.path.join(args.res_dir, 'log.txt')\n",
        "# Save command line input.\n",
        "cmd_input = 'python ' + ' '.join(sys.argv) + '\\n'\n",
        "with open(os.path.join(args.res_dir, 'cmd_input.txt'), 'a') as f:\n",
        "    f.write(cmd_input)\n",
        "print('Command line input: ' + cmd_input + ' is saved.')\n",
        "with open(log_file, 'a') as f:\n",
        "    f.write('\\n' + cmd_input)\n",
        "\n",
        "if args.dataset.startswith('ogbl'):\n",
        "    dataset = PygLinkPropPredDataset(name=args.dataset)\n",
        "    split_edge = dataset.get_edge_split()\n",
        "    data = dataset[0]\n",
        "    if args.dataset.startswith('ogbl-vessel'):\n",
        "        # normalize node features\n",
        "        data.x[:, 0] = torch.nn.functional.normalize(data.x[:, 0], dim=0)\n",
        "        data.x[:, 1] = torch.nn.functional.normalize(data.x[:, 1], dim=0)\n",
        "        data.x[:, 2] = torch.nn.functional.normalize(data.x[:, 2], dim=0)\n",
        "\n",
        "##=============Agregado para usar el dataset de actores=========\n",
        "if args.dataset.startswith('actor'):\n",
        "    path = osp.join('dataset')\n",
        "    dataset=Actor(path)\n",
        "    split_edge = do_edge_split(dataset)\n",
        "    data = dataset[0]\n",
        "    data.edge_index = split_edge['train']['edge'].t()\n",
        "##=============================================================\n",
        "\n",
        "if args.dataset.startswith('ogbl-citation'):\n",
        "    args.eval_metric = 'mrr'\n",
        "    directed = True\n",
        "elif args.dataset.startswith('ogbl-vessel'):\n",
        "    args.eval_metric = 'rocauc'\n",
        "    directed = False\n",
        "elif args.dataset.startswith('ogbl'):\n",
        "    args.eval_metric = 'hits'\n",
        "    directed = False\n",
        "else:  # assume other datasets are undirected (Usaremos esta para medir el dataset de actores)\n",
        "    args.eval_metric = 'auc'\n",
        "    directed = False\n",
        "\n",
        "if args.use_valedges_as_input:\n",
        "    val_edge_index = split_edge['valid']['edge'].t()\n",
        "    if not directed:\n",
        "        val_edge_index = to_undirected(val_edge_index)\n",
        "    data.edge_index = torch.cat([data.edge_index, val_edge_index], dim=-1)\n",
        "    if 'edge_weight' in data:\n",
        "        val_edge_weight = torch.ones([val_edge_index.size(1), 1], dtype=int)\n",
        "        data.edge_weight = torch.cat([data.edge_weight, val_edge_weight], 0)\n",
        "\n",
        "if args.dataset.startswith('ogbl'):\n",
        "    evaluator = Evaluator(name=args.dataset)\n",
        "if args.eval_metric == 'hits':\n",
        "    loggers = {\n",
        "        'Hits@20': Logger(args.runs, args),\n",
        "        'Hits@50': Logger(args.runs, args),\n",
        "        'Hits@100': Logger(args.runs, args),\n",
        "    }\n",
        "elif args.eval_metric == 'mrr':\n",
        "    loggers = {\n",
        "        'MRR': Logger(args.runs, args),\n",
        "    }\n",
        "elif args.eval_metric == 'rocauc':\n",
        "    loggers = {\n",
        "        'rocauc': Logger(args.runs, args),\n",
        "    }\n",
        "\n",
        "elif args.eval_metric == 'auc':\n",
        "    loggers = {\n",
        "        'AUC': Logger(args.runs, args),\n",
        "    }\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "if args.use_heuristic:\n",
        "    # Test link prediction heuristics.\n",
        "    num_nodes = data.num_nodes\n",
        "    if 'edge_weight' in data:\n",
        "        edge_weight = data.edge_weight.view(-1)\n",
        "    else:\n",
        "        edge_weight = torch.ones(data.edge_index.size(1), dtype=int)\n",
        "\n",
        "    A = ssp.csr_matrix((edge_weight, (data.edge_index[0], data.edge_index[1])),\n",
        "                       shape=(num_nodes, num_nodes))\n",
        "\n",
        "    pos_val_edge, neg_val_edge = get_pos_neg_edges('valid', split_edge,\n",
        "                                                   data.edge_index,\n",
        "                                                   data.num_nodes)\n",
        "    pos_test_edge, neg_test_edge = get_pos_neg_edges('test', split_edge,\n",
        "                                                     data.edge_index,\n",
        "                                                     data.num_nodes)\n",
        "    pos_val_pred, pos_val_edge = eval(args.use_heuristic)(A, pos_val_edge)\n",
        "    neg_val_pred, neg_val_edge = eval(args.use_heuristic)(A, neg_val_edge)\n",
        "    pos_test_pred, pos_test_edge = eval(args.use_heuristic)(A, pos_test_edge)\n",
        "    neg_test_pred, neg_test_edge = eval(args.use_heuristic)(A, neg_test_edge)\n",
        "\n",
        "    if args.eval_metric == 'hits':\n",
        "        results = evaluate_hits(pos_val_pred, neg_val_pred, pos_test_pred, neg_test_pred)\n",
        "    elif args.eval_metric == 'mrr':\n",
        "        results = evaluate_mrr(pos_val_pred, neg_val_pred, pos_test_pred, neg_test_pred)\n",
        "    elif args.eval_metric == 'rocauc':\n",
        "        results = evaluate_ogb_rocauc(pos_val_pred, neg_val_pred, pos_test_pred, neg_test_pred)\n",
        "    elif args.eval_metric == 'auc':\n",
        "        val_pred = torch.cat([pos_val_pred, neg_val_pred])\n",
        "        val_true = torch.cat([torch.ones(pos_val_pred.size(0), dtype=int),\n",
        "                              torch.zeros(neg_val_pred.size(0), dtype=int)])\n",
        "        test_pred = torch.cat([pos_test_pred, neg_test_pred])\n",
        "        test_true = torch.cat([torch.ones(pos_test_pred.size(0), dtype=int),\n",
        "                              torch.zeros(neg_test_pred.size(0), dtype=int)])\n",
        "        results = evaluate_auc(val_pred, val_true, test_pred, test_true)\n",
        "\n",
        "    for key, result in results.items():\n",
        "        loggers[key].add_result(0, result)\n",
        "    for key in loggers.keys():\n",
        "        print(key)\n",
        "        loggers[key].print_statistics()\n",
        "        with open(log_file, 'a') as f:\n",
        "            print(key, file=f)\n",
        "            loggers[key].print_statistics(f=f)\n",
        "    pdb.set_trace()\n",
        "    exit()\n",
        "\n",
        "\n",
        "#================================================================================================================================\n",
        "# =========================================================SEAL==================================================================\n",
        "#================================================================================================================================\n",
        "path = dataset.root + '_seal{}'.format(args.data_appendix)\n",
        "use_coalesce = True if args.dataset == 'ogbl-collab' else False\n",
        "if not args.dynamic_train and not args.dynamic_val and not args.dynamic_test:\n",
        "    args.num_workers = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVmnm5E5i4-b",
        "outputId": "405384a5-c2d2-407a-edeb-06cd7fa341fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results will be saved in results/actor_20240825045854\n",
            "Command line input: python /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-650ce9f7-1c2f-451a-80c7-fcedda2981df.json\n",
            " is saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_class = 'SEALDynamicDataset' if args.dynamic_train else 'SEALDataset'\n",
        "train_dataset = eval(dataset_class)( #Evalúa el dataset\n",
        "    path,\n",
        "    data,\n",
        "    split_edge,\n",
        "    num_hops=args.num_hops,\n",
        "    percent=args.train_percent,\n",
        "    split='train',\n",
        "    use_coalesce=use_coalesce,\n",
        "    node_label=args.node_label,\n",
        "    ratio_per_hop=args.ratio_per_hop,\n",
        "    max_nodes_per_hop=args.max_nodes_per_hop,\n",
        "    directed=directed,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vvYeIu_nzWJ",
        "outputId": "14a3a1d7-6eee-4eec-f08c-be42cf8c6a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "100%|██████████| 12744/12744 [00:49<00:00, 257.83it/s]\n",
            "100%|██████████| 12744/12744 [00:50<00:00, 250.87it/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if False:  # visualize some graphs\n",
        "    import networkx as nx\n",
        "    from torch_geometric.utils import to_networkx\n",
        "    import matplotlib\n",
        "    matplotlib.use(\"Agg\")\n",
        "    import matplotlib.pyplot as plt\n",
        "    loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
        "    for g in loader:\n",
        "        f = plt.figure(figsize=(20, 20))\n",
        "        limits = plt.axis('off')\n",
        "        g = g.to(device)\n",
        "        node_size = 100\n",
        "        with_labels = True\n",
        "        G = to_networkx(g, node_attrs=['z'])\n",
        "        labels = {i: G.nodes[i]['z'] for i in range(len(G))}\n",
        "        nx.draw(G, node_size=node_size, arrows=True, with_labels=with_labels,\n",
        "                labels=labels)\n",
        "        f.savefig('tmp_vis.png')\n",
        "        pdb.set_trace()"
      ],
      "metadata": {
        "id": "y3473b2An2NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_class = 'SEALDynamicDataset' if args.dynamic_val else 'SEALDataset'\n",
        "val_dataset = eval(dataset_class)(\n",
        "    path,\n",
        "    data,\n",
        "    split_edge,\n",
        "    num_hops=args.num_hops,\n",
        "    percent=args.val_percent,\n",
        "    split='valid',\n",
        "    use_coalesce=use_coalesce,\n",
        "    node_label=args.node_label,\n",
        "    ratio_per_hop=args.ratio_per_hop,\n",
        "    max_nodes_per_hop=args.max_nodes_per_hop,\n",
        "    directed=directed,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TGDNZQin4aj",
        "outputId": "d89355f1-20bc-452d-e1fa-65af40dda61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "100%|██████████| 149/149 [00:02<00:00, 54.83it/s]\n",
            "100%|██████████| 149/149 [00:00<00:00, 201.72it/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_class = 'SEALDynamicDataset' if args.dynamic_test else 'SEALDataset'\n",
        "test_dataset = eval(dataset_class)(\n",
        "    path,\n",
        "    data,\n",
        "    split_edge,\n",
        "    num_hops=args.num_hops,\n",
        "    percent=args.test_percent,\n",
        "    split='test',\n",
        "    use_coalesce=use_coalesce,\n",
        "    node_label=args.node_label,\n",
        "    ratio_per_hop=args.ratio_per_hop,\n",
        "    max_nodes_per_hop=args.max_nodes_per_hop,\n",
        "    directed=directed,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9-muVBeMWHQ",
        "outputId": "02364a99-d579-44f7-d3a6-43bf0035f3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "100%|██████████| 449/449 [00:01<00:00, 257.14it/s]\n",
            "100%|██████████| 449/449 [00:01<00:00, 279.11it/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_z = 1000  # set a large max_z so that every z has embeddings to look up\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=args.batch_size,\n",
        "                          shuffle=True, num_workers=args.num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=args.batch_size,\n",
        "                        num_workers=args.num_workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=args.batch_size,\n",
        "                         num_workers=args.num_workers)"
      ],
      "metadata": {
        "id": "ijlLQMCFMeB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if args.train_node_embedding:\n",
        "    emb = torch.nn.Embedding(data.num_nodes, args.hidden_channels).to(device)\n",
        "elif args.pretrained_node_embedding:\n",
        "    weight = torch.load(args.pretrained_node_embedding)\n",
        "    emb = torch.nn.Embedding.from_pretrained(weight)\n",
        "    emb.weight.requires_grad=False\n",
        "else:\n",
        "    emb = None\n"
      ],
      "metadata": {
        "id": "SgR4K4z_Mnpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for run in range(args.runs):\n",
        "    if args.model == 'DGCNN':\n",
        "        model = DGCNN(args.hidden_channels, args.num_layers, max_z, args.sortpool_k,\n",
        "                      train_dataset, args.dynamic_train, use_feature=args.use_feature,\n",
        "                      node_embedding=emb).to(device)\n",
        "    elif args.model == 'SAGE':\n",
        "        model = SAGE(args.hidden_channels, args.num_layers, max_z, train_dataset,\n",
        "                     args.use_feature, node_embedding=emb).to(device)\n",
        "    elif args.model == 'GCN':\n",
        "        model = GCN(args.hidden_channels, args.num_layers, max_z, train_dataset,\n",
        "                    args.use_feature, node_embedding=emb).to(device)\n",
        "    elif args.model == 'GIN':\n",
        "        model = GIN(args.hidden_channels, args.num_layers, max_z, train_dataset,\n",
        "                    args.use_feature, node_embedding=emb).to(device)\n",
        "    parameters = list(model.parameters())\n",
        "    if args.train_node_embedding:\n",
        "        torch.nn.init.xavier_uniform_(emb.weight)\n",
        "        parameters += list(emb.parameters())\n",
        "    optimizer = torch.optim.Adam(params=parameters, lr=args.lr)\n",
        "    total_params = sum(p.numel() for param in parameters for p in param)\n",
        "    print(f'Total number of parameters is {total_params}')\n",
        "    if args.model == 'DGCNN':\n",
        "        print(f'SortPooling k is set to {model.k}')\n",
        "    with open(log_file, 'a') as f:\n",
        "        print(f'Total number of parameters is {total_params}', file=f)\n",
        "        if args.model == 'DGCNN':\n",
        "            print(f'SortPooling k is set to {model.k}', file=f)\n",
        "\n",
        "    start_epoch = 1\n",
        "    if args.continue_from is not None:\n",
        "        model.load_state_dict(\n",
        "            torch.load(os.path.join(args.res_dir,\n",
        "                'run{}_model_checkpoint{}.pth'.format(run+1, args.continue_from)))\n",
        "        )\n",
        "        optimizer.load_state_dict(\n",
        "            torch.load(os.path.join(args.res_dir,\n",
        "                'run{}_optimizer_checkpoint{}.pth'.format(run+1, args.continue_from)))\n",
        "        )\n",
        "        start_epoch = args.continue_from + 1\n",
        "        args.epochs -= args.continue_from\n",
        "\n",
        "    if args.only_test:\n",
        "        results = test()\n",
        "        for key, result in results.items():\n",
        "            loggers[key].add_result(run, result)\n",
        "        for key, result in results.items():\n",
        "            valid_res, test_res = result\n",
        "            print(key)\n",
        "            print(f'Run: {run + 1:02d}, '\n",
        "                  f'Valid: {100 * valid_res:.2f}%, '\n",
        "                  f'Test: {100 * test_res:.2f}%')\n",
        "        pdb.set_trace()\n",
        "        exit()\n",
        "\n",
        "    #if args.test_multiple_models:\n",
        "    #    model_paths = [\n",
        "    #    ] # enter all your pretrained .pth model paths here\n",
        "    #    models = []\n",
        "    #    for path in model_paths:\n",
        "    #        m = cp.deepcopy(model)\n",
        "    #        m.load_state_dict(torch.load(path))\n",
        "    #        models.append(m)\n",
        "    #    Results = test_multiple_models(models)\n",
        "    #    for i, path in enumerate(model_paths):\n",
        "    #        print(path)\n",
        "    #        with open(log_file, 'a') as f:\n",
        "    #            print(path, file=f)\n",
        "    #        results = Results[i]\n",
        "    #        for key, result in results.items():\n",
        "    #            loggers[key].add_result(run, result)\n",
        "    #        for key, result in results.items():\n",
        "    #            valid_res, test_res = result\n",
        "    #            to_print = (f'Run: {run + 1:02d}, ' +\n",
        "    #                        f'Valid: {100 * valid_res:.2f}%, ' +\n",
        "    #                        f'Test: {100 * test_res:.2f}%')\n",
        "    #            print(key)\n",
        "    #            print(to_print)\n",
        "    #            with open(log_file, 'a') as f:\n",
        "    #                print(key, file=f)\n",
        "    #                print(to_print, file=f)\n",
        "    #    pdb.set_trace()\n",
        "    #    exit()\n",
        "\n",
        "    # Training starts\n",
        "    for epoch in range(start_epoch, start_epoch + args.epochs):\n",
        "        loss = train()\n",
        "\n",
        "        if epoch % args.eval_steps == 0:\n",
        "            results = test()\n",
        "            for key, result in results.items():\n",
        "                loggers[key].add_result(run, result)\n",
        "\n",
        "            if epoch % args.log_steps == 0:\n",
        "                model_name = os.path.join(\n",
        "                    args.res_dir, 'run{}_model_checkpoint{}.pth'.format(run+1, epoch))\n",
        "                optimizer_name = os.path.join(\n",
        "                    args.res_dir, 'run{}_optimizer_checkpoint{}.pth'.format(run+1, epoch))\n",
        "                torch.save(model.state_dict(), model_name)\n",
        "                torch.save(optimizer.state_dict(), optimizer_name)\n",
        "\n",
        "                for key, result in results.items():\n",
        "                    valid_res, test_res = result\n",
        "                    to_print = (f'Run: {run + 1:02d}, Epoch: {epoch:02d}, ' +\n",
        "                                f'Loss: {loss:.4f}, Valid: {100 * valid_res:.2f}%, ' +\n",
        "                                f'Test: {100 * test_res:.2f}%')\n",
        "                    print(key)\n",
        "                    print(to_print)\n",
        "                    with open(log_file, 'a') as f:\n",
        "                        print(key, file=f)\n",
        "                        print(to_print, file=f)\n",
        "\n",
        "    for key in loggers.keys():\n",
        "        print(key)\n",
        "        loggers[key].print_statistics(run)\n",
        "        with open(log_file, 'a') as f:\n",
        "            print(key, file=f)\n",
        "            loggers[key].print_statistics(run, f=f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWAluG0LM1pe",
        "outputId": "c79a1df5-8f02-45af-c699-7ee656d30bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters is 38369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:18<00:00, 42.86it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 109.68it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 80.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 01, Loss: 0.6783, Valid: 78.77%, Test: 78.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.09it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 72.14it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 60.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 02, Loss: 0.6089, Valid: 80.24%, Test: 79.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.97it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 99.89it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 85.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 03, Loss: 0.5773, Valid: 81.29%, Test: 81.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.80it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 102.01it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 94.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 04, Loss: 0.5595, Valid: 81.67%, Test: 81.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 53.09it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 110.04it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 85.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 05, Loss: 0.5456, Valid: 82.04%, Test: 81.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.47it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 101.62it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 87.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 06, Loss: 0.5331, Valid: 82.21%, Test: 81.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:16<00:00, 49.58it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 55.78it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 54.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 07, Loss: 0.5273, Valid: 82.28%, Test: 81.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 50.74it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 102.88it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 87.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 08, Loss: 0.5273, Valid: 82.70%, Test: 82.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.39it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 100.83it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 90.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 09, Loss: 0.5202, Valid: 82.68%, Test: 82.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.82it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 85.31it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 85.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 10, Loss: 0.5182, Valid: 82.83%, Test: 82.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.23it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 101.87it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 95.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 11, Loss: 0.5140, Valid: 83.00%, Test: 82.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 50.21it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 78.23it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 68.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 12, Loss: 0.5127, Valid: 82.87%, Test: 82.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 49.95it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 100.31it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 94.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 13, Loss: 0.5147, Valid: 82.88%, Test: 82.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.98it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 90.45it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 90.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 14, Loss: 0.5127, Valid: 82.74%, Test: 82.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 53.07it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 104.47it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 96.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 15, Loss: 0.5123, Valid: 83.00%, Test: 82.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:14<00:00, 53.24it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 104.30it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 87.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 16, Loss: 0.5089, Valid: 82.89%, Test: 82.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.37it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 104.73it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 94.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 17, Loss: 0.5126, Valid: 82.66%, Test: 82.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 49.90it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 54.32it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 62.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 18, Loss: 0.5111, Valid: 82.69%, Test: 82.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.60it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 100.71it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 94.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 19, Loss: 0.5086, Valid: 83.07%, Test: 82.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.77it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 104.95it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 93.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 20, Loss: 0.5090, Valid: 83.11%, Test: 82.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.47it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 102.31it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 96.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 21, Loss: 0.5096, Valid: 82.64%, Test: 82.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.06it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 95.22it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 90.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 22, Loss: 0.5067, Valid: 82.77%, Test: 82.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.50it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 78.58it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 64.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 23, Loss: 0.5081, Valid: 83.06%, Test: 82.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 50.92it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 71.35it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 71.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 24, Loss: 0.5081, Valid: 82.85%, Test: 82.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:14<00:00, 53.19it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 106.41it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 99.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 25, Loss: 0.5086, Valid: 82.76%, Test: 82.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.91it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 86.92it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 92.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 26, Loss: 0.5076, Valid: 82.73%, Test: 82.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.85it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 101.67it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 98.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 27, Loss: 0.5069, Valid: 83.15%, Test: 82.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.40it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 89.04it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 95.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 28, Loss: 0.5054, Valid: 82.60%, Test: 82.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 50.87it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 68.42it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 69.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 29, Loss: 0.5057, Valid: 82.80%, Test: 82.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:16<00:00, 49.81it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 80.58it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 89.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 30, Loss: 0.5042, Valid: 83.10%, Test: 82.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.49it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 111.21it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 93.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 31, Loss: 0.5060, Valid: 83.12%, Test: 82.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.46it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 96.63it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 95.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 32, Loss: 0.5067, Valid: 82.79%, Test: 82.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:14<00:00, 53.17it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 84.84it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 88.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 33, Loss: 0.5055, Valid: 82.82%, Test: 82.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 53.08it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 101.08it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 93.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 34, Loss: 0.5057, Valid: 82.77%, Test: 82.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.46it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 71.16it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 60.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 35, Loss: 0.5024, Valid: 82.78%, Test: 82.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.18it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 102.27it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 92.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 36, Loss: 0.5033, Valid: 83.16%, Test: 82.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:14<00:00, 53.27it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 102.45it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 82.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 37, Loss: 0.5046, Valid: 83.17%, Test: 82.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 53.09it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 103.76it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 92.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 38, Loss: 0.5056, Valid: 83.13%, Test: 82.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.83it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 103.87it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 88.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 39, Loss: 0.5028, Valid: 83.17%, Test: 82.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.43it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 105.43it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 83.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 40, Loss: 0.5040, Valid: 83.10%, Test: 82.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:16<00:00, 49.43it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 70.89it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 62.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 41, Loss: 0.5026, Valid: 83.14%, Test: 82.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.27it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 89.28it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 86.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 42, Loss: 0.5035, Valid: 83.18%, Test: 82.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.61it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 88.82it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 88.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 43, Loss: 0.5005, Valid: 83.22%, Test: 82.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.45it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 108.14it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 88.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 44, Loss: 0.5030, Valid: 83.16%, Test: 82.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.38it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 87.69it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 91.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 45, Loss: 0.5015, Valid: 83.16%, Test: 82.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 51.76it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 70.24it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 61.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 46, Loss: 0.5019, Valid: 83.21%, Test: 82.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 50.55it/s]\n",
            "100%|█████████████████████████████████| 10/10 [00:00<00:00, 97.25it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 92.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 47, Loss: 0.5010, Valid: 83.20%, Test: 82.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.15it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 101.47it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 86.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 48, Loss: 0.5044, Valid: 83.19%, Test: 82.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.99it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 104.24it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 88.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 49, Loss: 0.5025, Valid: 83.14%, Test: 82.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████| 797/797 [00:15<00:00, 52.17it/s]\n",
            "100%|████████████████████████████████| 10/10 [00:00<00:00, 108.78it/s]\n",
            "100%|█████████████████████████████████| 29/29 [00:00<00:00, 93.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "Run: 01, Epoch: 50, Loss: 0.5012, Valid: 83.22%, Test: 82.44%\n",
            "AUC\n",
            "Run 01:\n",
            "Highest Valid: 83.22\n",
            "Highest Eval Point: 43\n",
            "   Final Test: 82.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in loggers.keys():\n",
        "    print(key)\n",
        "    loggers[key].print_statistics()\n",
        "print(f'Total number of parameters is {total_params}')\n",
        "print(f'Results are saved in {args.res_dir}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU5HilCaNBam",
        "outputId": "2d0b0e92-ae53-4413-c089-60e53e343936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC\n",
            "All runs:\n",
            "Highest Valid: 83.22 ± nan\n",
            "   Final Test: 82.42 ± nan\n",
            "Total number of parameters is 38369\n",
            "Results are saved in results/actor_20240825044144\n"
          ]
        }
      ]
    }
  ]
}
